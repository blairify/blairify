{
  "mcq_questions": [],
  "open_questions": [
    {
      "id": "b3a445e4-49ab-4d7f-99f9-4a2bdf4857a9",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Explain the Virtual DOM in React",
      "description": "In your own words, explain what the Virtual DOM is in React, why it exists, and how it benefits frontend development.",
      "prompt": "Explain the Virtual DOM in React, including its purpose, how it works, and why it improves performance for frontend applications.",
      "topic": "frontend",
      "subtopics": [
        "react",
        "performance",
        "fundamentals"
      ],
      "tags": [
        "virtual-dom",
        "react",
        "rendering"
      ],
      "estimatedTimeMinutes": 7,
      "aiEvaluationHint": "Expect a clear explanation that the Virtual DOM is an in-memory representation of the real DOM, used by React to optimize UI updates. The answer should mention that React compares the Virtual DOM to the actual DOM and only updates changed elements, improving performance. Penalize answers that omit the performance aspect or confuse how the Virtual DOM works.",
      "companies": [
        {
          "name": "Meta",
          "logo": "SiMeta",
          "size": [
            "faang"
          ],
          "description": "Meta is the creator of React, a leading frontend library."
        }
      ],
      "positions": [
        "frontend"
      ],
      "primaryTechStack": [
        "react",
        "javascript"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-28T12:00:00Z",
      "updatedAt": "2024-06-28T12:00:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "fa2b9f93-7bbd-4a17-ab1b-bc0162b5ddc7",
          "text": "The Virtual DOM is a lightweight copy of the real DOM that React uses to determine what changed in the UI. React updates the Virtual DOM first, compares it to a previous version, and only applies the minimal necessary changes to the actual DOM. This makes updates more efficient and improves performance.",
          "keyPoints": [
            "Virtual DOM is a copy of the real DOM",
            "React updates the Virtual DOM first",
            "React compares previous and current Virtual DOM to identify changes",
            "Only necessary changes are applied to the real DOM",
            "Performance improvement"
          ]
        }
      ]
    },
    {
      "id": "6fa6f1e9-4eae-4e3d-8d1f-8b5ddaf96c7b",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Describe the role of CSS Flexbox in layout",
      "description": "Briefly describe what CSS Flexbox is and give an example scenario where you would use it in a frontend project.",
      "prompt": "Describe CSS Flexbox, its purpose in web layouts, and provide a typical use case where it would be a good choice.",
      "topic": "frontend",
      "subtopics": [
        "css",
        "layout",
        "fundamentals"
      ],
      "tags": [
        "css",
        "flexbox",
        "layout"
      ],
      "estimatedTimeMinutes": 6,
      "aiEvaluationHint": "The best answer explains that Flexbox is a CSS layout model for arranging items in one dimension (row or column), making it easier to design flexible and responsive layouts. A good example use case is centering items horizontally and vertically in a container or creating navigation bars. Partial credit for mentioning only basic layout.",
      "companies": [
        {
          "name": "Adobe",
          "logo": "SiAdobe",
          "size": [
            "enterprise"
          ],
          "description": "Adobe develops creative tools and web technologies."
        }
      ],
      "positions": [
        "frontend"
      ],
      "primaryTechStack": [
        "css",
        "html"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "flash"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-28T12:01:00Z",
      "updatedAt": "2024-06-28T12:01:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "2b7e8dcb-6f62-4c14-8dcd-5c5b2d7c5a5a",
          "text": "CSS Flexbox is a layout model that allows items within a container to be arranged and aligned easily in a row or a column. I would use Flexbox to center a group of buttons both horizontally and vertically inside a modal dialog.",
          "keyPoints": [
            "Flexbox is for one-dimensional layouts",
            "Simplifies alignment and spacing",
            "Example use case (centering, nav bars, etc.)"
          ]
        }
      ]
    },
    {
      "id": "1e8e2b7c-bb8c-4d8b-8c1f-9089e5b8b7e1",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "faang",
      "title": "Debugging a slow single-page application (SPA)",
      "description": "You notice that a React-based single-page application is becoming increasingly slow as users navigate between views. What are some possible causes of this slowdown, and how would you approach diagnosing and fixing it?",
      "prompt": "List at least three possible reasons why a React SPA could slow down over time when navigating between views. Explain how you would diagnose the root cause and outline steps for resolving the issue.",
      "topic": "frontend",
      "subtopics": [
        "performance",
        "react",
        "debugging"
      ],
      "tags": [
        "debugging",
        "performance",
        "spa",
        "react"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Look for identification of memory leaks (such as uncleaned event listeners), excessive re-renders, large component trees, or unnecessary data fetching. A strong answer should mention use of browser DevTools, React Profiler, and steps like profiling components, checking memory usage, and optimizing rendering. Penalize vague answers or those that focus only on code optimization without analysis.",
      "companies": [
        {
          "name": "Netflix",
          "logo": "SiNetflix",
          "size": [
            "faang"
          ],
          "description": "Netflix builds high-performance web apps for streaming."
        }
      ],
      "positions": [
        "frontend"
      ],
      "primaryTechStack": [
        "react",
        "javascript",
        "chrome-devtools"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "competitive"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-28T12:02:00Z",
      "updatedAt": "2024-06-28T12:02:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "e1b3f2c4-7cd8-4e1f-9f79-2b5acf993a3c",
          "text": "Possible causes include memory leaks from not cleaning up event listeners, excessive re-rendering due to poor state management, or components that don't unmount properly. I would use browser DevTools to monitor memory usage and the React Profiler to find slow components. Fixes may involve optimizing component lifecycles, caching, or splitting large components.",
          "keyPoints": [
            "Identifies memory leaks, excessive re-renders, inefficient components",
            "Mentions use of DevTools and React Profiler",
            "Outlines diagnosis and remediation steps"
          ]
        }
      ]
    },
    {
      "id": "c4f3d8b2-4e47-4a7e-9f46-9e9c4cc7b35a",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "startup",
      "title": "Accessibility considerations for forms",
      "description": "A product manager asks you to review a web form for accessibility. What key aspects would you check to ensure the form is accessible to all users?",
      "prompt": "List at least three important accessibility checks to perform when reviewing a web form. Explain why each is important and how to address any issues.",
      "topic": "frontend",
      "subtopics": [
        "accessibility",
        "forms",
        "usability"
      ],
      "tags": [
        "a11y",
        "accessibility",
        "forms"
      ],
      "estimatedTimeMinutes": 8,
      "aiEvaluationHint": "Strong answers mention using semantic labels, ensuring all form fields have associated labels, keyboard navigation, and ARIA attributes if needed. Answers should explain why each is necessary (e.g., for screen readers or users who can't use a mouse). Partial credit for listing only one or two aspects.",
      "companies": [
        {
          "name": "Vercel",
          "logo": "SiVercel",
          "size": [
            "startup"
          ],
          "description": "Vercel builds modern frontend deployment infrastructure."
        }
      ],
      "positions": [
        "frontend"
      ],
      "primaryTechStack": [
        "html",
        "css",
        "javascript"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-28T12:03:00Z",
      "updatedAt": "2024-06-28T12:03:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "a465d3e2-7b6a-44e7-9a14-fb1e2b5b9d41",
          "text": "I would check that each form field has a corresponding label, test that all form interactions can be done with a keyboard, and ensure error messages are announced to screen readers. Proper use of ARIA attributes and semantic HTML is also important.",
          "keyPoints": [
            "Form fields have labels",
            "Keyboard navigation works",
            "Error messages are accessible",
            "Use of ARIA/semantic HTML"
          ]
        }
      ]
    },
    {
      "id": "f5e8b9d7-8fc6-4c4e-91d6-89dcb7a2a7f1",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "faang",
      "title": "State management in large React apps",
      "description": "When would you recommend using an external state management library (like Redux or Zustand) rather than React's built-in state? What factors should influence this decision?",
      "prompt": "Explain scenarios where external state management in React is appropriate, and discuss the trade-offs compared to React's built-in state.",
      "topic": "frontend",
      "subtopics": [
        "react",
        "state-management",
        "architecture"
      ],
      "tags": [
        "react",
        "state",
        "redux",
        "zustand",
        "architecture"
      ],
      "estimatedTimeMinutes": 9,
      "aiEvaluationHint": "Look for discussion of scale/complexity, cross-component or global state, and maintainability. Strong answers mention trade-offs such as increased complexity and boilerplate, and give examples (e.g., cross-component communication, shared global state). Penalize answers that just list library names or don't discuss trade-offs.",
      "companies": [
        {
          "name": "Google",
          "logo": "SiGoogle",
          "size": [
            "faang"
          ],
          "description": "Google builds large-scale, complex frontend applications."
        }
      ],
      "positions": [
        "frontend"
      ],
      "primaryTechStack": [
        "react",
        "redux",
        "zustand",
        "javascript"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-28T12:04:00Z",
      "updatedAt": "2024-06-28T12:04:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "e4f9dc8c-5a2e-4c3e-9e3f-6c6f2d6a8b1d",
          "text": "External state management is useful when many components need to share state or in large apps where state logic becomes complex. For small, isolated state, React's built-in useState/useContext is better. Libraries like Redux add structure but also complexity and boilerplate, so I would use them only if the app's state requirements outgrow what React alone can handle.",
          "keyPoints": [
            "External state for global/cross-component state",
            "Built-in state for simple/local state",
            "Trade-offs: complexity, boilerplate",
            "Use cases: large apps, complex state flows"
          ]
        }
      ]
    },
    {
      "id": "a9d8f8c7-ff32-42a9-ae38-1a6b6e7f5cfa",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Optimizing frontend performance for mobile users",
      "description": "A significant portion of your web app's traffic comes from mobile devices on slow connections. What steps would you take to optimize performance, and how would you measure the impact of your changes?",
      "prompt": "Describe a strategy for improving frontend performance for mobile users on slow connections. Include both code and tooling considerations, and explain how you would verify improvements.",
      "topic": "frontend",
      "subtopics": [
        "performance",
        "mobile",
        "optimization"
      ],
      "tags": [
        "performance",
        "mobile",
        "optimization",
        "metrics"
      ],
      "estimatedTimeMinutes": 12,
      "aiEvaluationHint": "Good answers discuss techniques like code splitting, image optimization, lazy loading, minimizing bundle size, and using performance budgets. They should mention tools like Lighthouse or WebPageTest for measurement. Penalize answers that only mention a single technique or don't consider measurement.",
      "companies": [
        {
          "name": "Salesforce",
          "logo": "SiSalesforce",
          "size": [
            "enterprise"
          ],
          "description": "Salesforce delivers cloud apps for a global, mobile-first audience."
        }
      ],
      "positions": [
        "frontend"
      ],
      "primaryTechStack": [
        "javascript",
        "react",
        "webpack"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "competitive"
      ],
      "seniorityLevels": [
        "mid",
        "junior"
      ],
      "createdAt": "2024-06-28T12:05:00Z",
      "updatedAt": "2024-06-28T12:05:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "c3e4b5a6-8f2a-4a6f-bb12-2b4d8c1d6f5d",
          "text": "I would optimize images (use srcset, compression), implement code splitting, enable lazy loading of non-critical assets, and reduce initial bundle size. I'd use Lighthouse to measure metrics like First Contentful Paint before and after changes to verify improvement.",
          "keyPoints": [
            "Mentions mobile-specific optimizations (image, code splitting, lazy loading)",
            "Considers performance measurement (Lighthouse/WebPageTest)",
            "Addresses both optimization and verification"
          ]
        }
      ]
    },
    {
      "id": "0d4e3e2a-3b2b-4e8d-9085-d4a1b7c7a2e2",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "startup",
      "title": "Handling API errors gracefully in frontend apps",
      "description": "Your web application relies on several external APIs. Sometimes, these APIs return errors or time out. How would you design your frontend to handle these failures and maintain a good user experience?",
      "prompt": "Explain a strategy for handling external API errors in a frontend application, ensuring users are informed appropriately and the app remains usable. Provide details on both technical implementation and user experience.",
      "topic": "frontend",
      "subtopics": [
        "api",
        "error-handling",
        "ux"
      ],
      "tags": [
        "api",
        "error",
        "handling",
        "ux"
      ],
      "estimatedTimeMinutes": 11,
      "aiEvaluationHint": "A strong answer explains catching errors, displaying helpful error messages (not just generic alerts), using retry logic or fallbacks, and ensuring the app remains stable. It should mention both technical implementation (try/catch, error boundaries) and user experience (clear feedback, possibly offline modes). Partial credit for only technical or only UX suggestions.",
      "companies": [
        {
          "name": "Stripe",
          "logo": "SiStripe",
          "size": [
            "startup"
          ],
          "description": "Stripe builds reliable APIs and cares about frontend resilience."
        }
      ],
      "positions": [
        "frontend"
      ],
      "primaryTechStack": [
        "react",
        "javascript",
        "api"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "competitive"
      ],
      "seniorityLevels": [
        "mid",
        "junior"
      ],
      "createdAt": "2024-06-28T12:06:00Z",
      "updatedAt": "2024-06-28T12:06:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "b1a2e3f4-7d8c-4b2a-9e6f-1f2d3c4e5b6d",
          "text": "I'd catch errors from API calls, show clear error messages to users, and offer ways to retry or fallback. For example, if fetching data fails, I might display a message and a retry button, and use error boundaries in React for UI errors. The app should not crash, and users should always know what's happening.",
          "keyPoints": [
            "Technical error handling (try/catch, error boundaries)",
            "Clear, user-friendly error messages",
            "Retry options or fallbacks",
            "App remains usable and informative"
          ]
        }
      ]
    },
    {
      "id": "c6b5e4f8-2d79-4c23-8b2c-2eb6f3b7e176",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Design a component library for a large organization",
      "description": "Imagine you are tasked with designing a reusable component library (design system) for all frontend teams in a large organization. What are the key technical and organizational challenges you expect to face, and how would you address them?",
      "prompt": "List at least three major challenges in building a shared component library at scale (both technical and organizational). For each, describe your approach to solving it.",
      "topic": "frontend",
      "subtopics": [
        "architecture",
        "design-system",
        "scalability"
      ],
      "tags": [
        "component-library",
        "design-system",
        "scalability",
        "collaboration"
      ],
      "estimatedTimeMinutes": 13,
      "aiEvaluationHint": "Top answers identify challenges like API consistency, versioning, documentation, onboarding, enforcing design standards, and team buy-in. Responses should address both technical (e.g., build tooling, theming, accessibility) and organizational (e.g., adoption, communication). Penalize answers that only mention low-level technical implementation.",
      "companies": [
        {
          "name": "Microsoft",
          "logo": "SiMicrosoft",
          "size": [
            "faang"
          ],
          "description": "Microsoft builds and maintains large-scale design systems."
        }
      ],
      "positions": [
        "frontend"
      ],
      "primaryTechStack": [
        "react",
        "typescript",
        "storybook"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-28T12:07:00Z",
      "updatedAt": "2024-06-28T12:07:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "f2e5c7d8-6c1b-42b7-8a37-4d5a2e7b7e9a",
          "text": "Challenges include ensuring API consistency (solved by strict linting and reviews), versioning and upgrade management (using semantic versioning and changelogs), and driving adoption (through documentation, demos, and team training). Also, maintaining accessibility and theming support is critical.",
          "keyPoints": [
            "API consistency",
            "Versioning and upgrade path",
            "Adoption and documentation",
            "Accessibility/theming"
          ]
        }
      ]
    },
    {
      "id": "f1b3a8e2-7c35-4d8c-8b9f-2e4b7c8a4e3f",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "senior",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Diagnose and resolve a Cumulative Layout Shift (CLS) issue",
      "description": "A high-traffic e-commerce site is experiencing poor user experience due to Cumulative Layout Shift (CLS). Explain how you would identify the root causes of CLS and implement solutions to eliminate it.",
      "prompt": "Describe a systematic approach to diagnosing and fixing Cumulative Layout Shift on a large frontend application. Include tools, common root causes, and at least two ways to prevent CLS.",
      "topic": "frontend",
      "subtopics": [
        "performance",
        "web-vitals",
        "ux"
      ],
      "tags": [
        "CLS",
        "web-vitals",
        "performance",
        "diagnostics"
      ],
      "estimatedTimeMinutes": 15,
      "aiEvaluationHint": "A comprehensive answer mentions using field and lab tools (e.g., Lighthouse, Chrome DevTools), identifies common causes (images without dimensions, late-loading ads, fonts), and proposes solutions (setting width/height, reserving space, optimizing font loading). Penalize answers that only describe tools or only list causes without solutions.",
      "companies": [
        {
          "name": "Amazon",
          "logo": "SiAmazon",
          "size": [
            "faang"
          ],
          "description": "Amazon cares deeply about frontend performance for e-commerce."
        }
      ],
      "positions": [
        "frontend"
      ],
      "primaryTechStack": [
        "javascript",
        "react",
        "web-vitals"
      ],
      "interviewTypes": [
        "regular",
        "competitive",
        "teacher"
      ],
      "seniorityLevels": [
        "senior",
        "mid"
      ],
      "createdAt": "2024-06-28T12:08:00Z",
      "updatedAt": "2024-06-28T12:08:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "b7d8e3a2-6e8c-4c2a-9f5d-5a7b4e3a8c2f",
          "text": "I would use Lighthouse and Chrome DevTools to identify where layout shifts occur. Common causes are images or ads loading without fixed dimensions and web fonts causing reflow. Solutions include always specifying width and height for images/media, reserving space for dynamic content, and using font-display: swap for fonts.",
          "keyPoints": [
            "Use field/lab tools for diagnosis",
            "Identify root causes (images, ads, fonts)",
            "Implement fixes (set dimensions, reserve space, optimize font loading)"
          ]
        }
      ]
    },
    {
      "id": "e2d3b7f6-2e16-4b3d-8b1e-5b4e9a2d3c7b",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "startup",
      "title": "Testing strategies for modern frontend applications",
      "description": "What types of automated tests would you recommend for a frontend application built with React, and how would you decide what to test at each level?",
      "prompt": "Explain the main types of automated testing for React apps (unit, integration, end-to-end) and how you would decide which features to test at each level. Give examples.",
      "topic": "frontend",
      "subtopics": [
        "testing",
        "react",
        "quality-assurance"
      ],
      "tags": [
        "testing",
        "unit-test",
        "integration-test",
        "e2e",
        "react"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Expect identification of unit, integration, and end-to-end tests. Strong answers explain when to use each (e.g., unit for logic, integration for component interaction, e2e for user flows) and provide examples. Penalize answers that only list test types without examples or rationale.",
      "companies": [
        {
          "name": "Airbnb",
          "logo": "SiAirbnb",
          "size": [
            "startup"
          ],
          "description": "Airbnb values frontend quality and test coverage."
        }
      ],
      "positions": [
        "frontend"
      ],
      "primaryTechStack": [
        "react",
        "jest",
        "cypress"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "junior"
      ],
      "createdAt": "2024-06-28T12:09:00Z",
      "updatedAt": "2024-06-28T12:09:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "f3e2c1b5-8a2e-4b7a-bd5f-9a9c2b6e8d1f",
          "text": "I recommend unit tests for pure functions and components, integration tests for component interactions (like form submissions), and end-to-end tests for real user flows (like booking a room). Prioritize unit tests for core logic, integration for key interactions, and e2e for critical user journeys.",
          "keyPoints": [
            "Unit, integration, and e2e tests",
            "When to use each",
            "Concrete examples for each type"
          ]
        }
      ]
    },
    {
      "id": "6d8a8b8c-2e3f-4b4d-862d-9e0e8aebc7a1",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "startup",
      "title": "Explaining RESTful API Principles",
      "description": "Briefly explain what it means for an API to be RESTful and describe at least two benefits of using a RESTful approach in backend development.",
      "prompt": "Explain what makes an API RESTful. List at least two benefits of using RESTful APIs in backend development.",
      "topic": "backend",
      "subtopics": [
        "api",
        "rest",
        "web-services",
        "http"
      ],
      "tags": [
        "api",
        "rest",
        "http",
        "backend"
      ],
      "estimatedTimeMinutes": 6,
      "aiEvaluationHint": "Look for an explanation that mentions statelessness, resource-based design, and standard HTTP methods. Benefits should include aspects like scalability, simplicity, separation of client and server, or ease of integration. Partial credit if only one benefit is given or the explanation is unclear.",
      "companies": [
        {
          "name": "Stripe",
          "logo": "SiStripe",
          "size": [
            "startup"
          ],
          "description": "Online payment processing for internet businesses."
        }
      ],
      "positions": [
        "backend"
      ],
      "primaryTechStack": [
        "nodejs",
        "express",
        "python",
        "django"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "flash",
        "teacher"
      ],
      "seniorityLevels": [
        "entry"
      ],
      "createdAt": "2024-06-10T09:00:00Z",
      "updatedAt": "2024-06-10T09:00:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "a1c2d3e4-f567-4c8e-b5c1-9e9a1b2c3d4e",
          "text": "A RESTful API follows principles like statelessness, resource-based URIs, and uses standard HTTP methods (GET, POST, PUT, DELETE). Benefits include simplicity and scalability, as well as easier integration with different clients.",
          "keyPoints": [
            "Statelessness and resource-based design",
            "Use of standard HTTP methods",
            "Scalability and simplicity",
            "Separation of client and server"
          ]
        }
      ]
    },
    {
      "id": "00b99b4a-9e7e-4a1d-8e5c-1980a4caa0d2",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Common Causes of 500 Internal Server Error",
      "description": "You're working on a backend API, and users are reporting frequent '500 Internal Server Error' responses. List two common causes for this error and briefly describe how you would start troubleshooting.",
      "prompt": "List two common reasons a backend API might return a 500 Internal Server Error. Suggest how you would begin investigating the root cause.",
      "topic": "backend",
      "subtopics": [
        "debugging",
        "http",
        "error-handling"
      ],
      "tags": [
        "http",
        "errors",
        "debugging",
        "backend"
      ],
      "estimatedTimeMinutes": 7,
      "aiEvaluationHint": "A good answer should mention server-side issues such as unhandled exceptions, database errors, or misconfigurations. Troubleshooting should include checking logs or error messages. Give partial credit if only one cause is mentioned, or if the troubleshooting steps are too vague.",
      "companies": [
        {
          "name": "Salesforce",
          "logo": "SiSalesforce",
          "size": [
            "enterprise"
          ],
          "description": "Cloud-based customer relationship management (CRM) software."
        }
      ],
      "positions": [
        "backend"
      ],
      "primaryTechStack": [
        "java",
        "spring",
        "nodejs"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "entry"
      ],
      "createdAt": "2024-06-10T09:10:00Z",
      "updatedAt": "2024-06-10T09:10:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "b3a4c5d6-e789-4f01-b2c3-4567e8f9a0b1",
          "text": "Common reasons for 500 Internal Server Error include unhandled exceptions in the application code and database connection failures. To troubleshoot, I would check the application logs for stack traces or error messages to identify the failing part.",
          "keyPoints": [
            "Unhandled exceptions",
            "Database errors",
            "Checking logs for error details"
          ]
        }
      ]
    },
    {
      "id": "8e4b53a4-2b7e-47d6-bd9a-2eb3bcf7e1c4",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "faang",
      "title": "Choosing a Database for User Data",
      "description": "You are asked to design the backend for a new social networking app. What factors would influence your choice between a relational database (like PostgreSQL) and a NoSQL database (like MongoDB) for storing user profiles? Name at least two considerations and explain your reasoning.",
      "prompt": "Describe factors that should influence the choice between using a relational database and a NoSQL database for user profile storage in a social networking backend. Explain at least two considerations.",
      "topic": "backend",
      "subtopics": [
        "databases",
        "architecture",
        "design"
      ],
      "tags": [
        "database",
        "relational",
        "nosql",
        "design"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Look for mention of data structure (e.g., need for complex queries or relationships favors relational), scalability, flexibility, and consistency requirements. Penalize answers that only list database names without explaining the trade-offs.",
      "companies": [
        {
          "name": "Meta",
          "logo": "SiMeta",
          "size": [
            "faang"
          ],
          "description": "Meta builds technologies to help people connect, find communities, and grow businesses."
        }
      ],
      "positions": [
        "backend"
      ],
      "primaryTechStack": [
        "nodejs",
        "mongodb",
        "postgresql"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior"
      ],
      "createdAt": "2024-06-10T09:20:00Z",
      "updatedAt": "2024-06-10T09:20:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "c4d5e6f7-1a2b-4c5d-8e9f-0a1b2c3d4e5f",
          "text": "If user profiles have structured data and require complex queries or relationships, a relational database like PostgreSQL is better. If the data model is flexible and needs to scale horizontally, NoSQL like MongoDB may be preferred. Data consistency and transaction requirements are also important factors.",
          "keyPoints": [
            "Data structure/relationships",
            "Flexibility and scalability",
            "Consistency and transaction requirements"
          ]
        }
      ]
    },
    {
      "id": "3c4da1b2-9e5d-4f4e-8c6a-3f1b2d7c8e9f",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "startup",
      "title": "Handling Authentication in a REST API",
      "description": "Describe two common methods for handling user authentication in a RESTful backend API. Briefly explain how each method works and mention a situation where one might be preferred over the other.",
      "prompt": "List two widely used techniques for user authentication in REST APIs. For each, explain the mechanism and give an example scenario where it is preferred.",
      "topic": "backend",
      "subtopics": [
        "authentication",
        "security",
        "api"
      ],
      "tags": [
        "authentication",
        "security",
        "rest",
        "api"
      ],
      "estimatedTimeMinutes": 9,
      "aiEvaluationHint": "Candidates should mention methods like JWT tokens, OAuth, or session-based authentication. Look for brief explanations of how they work and when each is suitable. Penalize if they only name methods without explanation.",
      "companies": [
        {
          "name": "Plandek",
          "logo": "SiPlandek",
          "size": [
            "startup"
          ],
          "description": "Analytics for software delivery teams."
        }
      ],
      "positions": [
        "backend"
      ],
      "primaryTechStack": [
        "nodejs",
        "express",
        "python",
        "flask"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior"
      ],
      "createdAt": "2024-06-10T09:30:00Z",
      "updatedAt": "2024-06-10T09:30:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "e6f7a8b9-0c1d-4e2f-b3a4-5c6d7e8f9a0b",
          "text": "Session-based authentication stores the session on the server, and clients use session IDs with each request. JWT tokens store authentication info in a token sent with each request; it's stateless. Sessions are better for web apps; JWTs are good for APIs and microservices.",
          "keyPoints": [
            "Session-based vs token-based (JWT) authentication",
            "How each method works",
            "Preferred use cases for each"
          ]
        }
      ]
    },
    {
      "id": "adfe1e8c-3d72-4c8e-a6e1-c43a0eae5e3f",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "faang",
      "title": "Improving Backend API Performance",
      "description": "A backend API endpoint is slow to respond when returning a list of products. What steps could you take to improve the response time? Provide at least two different strategies.",
      "prompt": "List and briefly explain at least two different approaches to improving the response time of a slow backend API endpoint that returns product data.",
      "topic": "backend",
      "subtopics": [
        "performance",
        "api",
        "optimization"
      ],
      "tags": [
        "performance",
        "optimization",
        "api",
        "backend"
      ],
      "estimatedTimeMinutes": 8,
      "aiEvaluationHint": "Answers should mention strategies like database query optimization, caching, reducing payload size, or using pagination. Points awarded for clear explanations and variety in the strategies.",
      "companies": [
        {
          "name": "Amazon",
          "logo": "SiAmazon",
          "size": [
            "faang"
          ],
          "description": "E-commerce, cloud computing, and digital streaming provider."
        }
      ],
      "positions": [
        "backend"
      ],
      "primaryTechStack": [
        "nodejs",
        "mongodb",
        "redis",
        "aws"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "flash",
        "teacher"
      ],
      "seniorityLevels": [
        "junior"
      ],
      "createdAt": "2024-06-10T09:40:00Z",
      "updatedAt": "2024-06-10T09:40:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "b8e9c0a1-2d3f-4a5b-b6c7-8d9e1f2a3b4c",
          "text": "You can add pagination to limit the amount of data sent, use caching (like Redis) to store frequent responses, and optimize database queries to fetch only necessary fields.",
          "keyPoints": [
            "Pagination",
            "Caching",
            "Database query optimization"
          ]
        }
      ]
    },
    {
      "id": "fae1d1ff-567e-4a0e-b1b5-5cbb8f7a2b3c",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Logging Best Practices in Backend Applications",
      "description": "Explain why logging is important in backend systems. What are two best practices for logging in production environments?",
      "prompt": "Describe the importance of logging in backend applications and list two best practices for logging in a production system.",
      "topic": "backend",
      "subtopics": [
        "logging",
        "operations",
        "monitoring"
      ],
      "tags": [
        "logging",
        "monitoring",
        "production"
      ],
      "estimatedTimeMinutes": 7,
      "aiEvaluationHint": "Look for an explanation that logging helps with monitoring, debugging, and auditing. Best practices might include using structured logs and avoiding sensitive information. Award partial credit for one best practice.",
      "companies": [
        {
          "name": "IBM",
          "logo": "SiIbm",
          "size": [
            "enterprise"
          ],
          "description": "Global technology and consulting company."
        }
      ],
      "positions": [
        "backend"
      ],
      "primaryTechStack": [
        "java",
        "spring",
        "python"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior"
      ],
      "createdAt": "2024-06-10T09:45:00Z",
      "updatedAt": "2024-06-10T09:45:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "d3e4f5a6-7b8c-4a9e-b1c2-3d4e5f6a7b8c",
          "text": "Logging is crucial for monitoring system health and diagnosing issues. Two best practices are: using structured log formats (like JSON) for easy parsing, and ensuring no sensitive data (like passwords) is logged.",
          "keyPoints": [
            "Monitoring and debugging",
            "Structured logging",
            "Avoid logging sensitive data"
          ]
        }
      ]
    },
    {
      "id": "f2a8e34d-61d5-4c9b-9f3b-7f1c2e9d8a7b",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Diagnosing Memory Leaks in Node.js Applications",
      "description": "A Node.js backend service is gradually consuming more memory over time and eventually crashes. How would you systematically identify and resolve a memory leak in this scenario?",
      "prompt": "Describe the steps you would take to diagnose and fix a memory leak in a Node.js backend service that crashes due to increasing memory usage.",
      "topic": "backend",
      "subtopics": [
        "debugging",
        "nodejs",
        "performance",
        "memory"
      ],
      "tags": [
        "nodejs",
        "memory",
        "debugging",
        "performance"
      ],
      "estimatedTimeMinutes": 14,
      "aiEvaluationHint": "A strong answer should mention monitoring memory usage (e.g., using tools like heap snapshots or process monitors), identifying code paths that retain references, using profiling tools, and fixing leaks by releasing unused objects. Penalize if they only mention restarting the service or vague solutions.",
      "companies": [
        {
          "name": "Netflix",
          "logo": "SiNetflix",
          "size": [
            "faang"
          ],
          "description": "Streaming entertainment service."
        }
      ],
      "positions": [
        "backend"
      ],
      "primaryTechStack": [
        "nodejs",
        "express",
        "aws"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher",
        "competitive"
      ],
      "seniorityLevels": [
        "mid"
      ],
      "createdAt": "2024-06-10T09:50:00Z",
      "updatedAt": "2024-06-10T09:50:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "e7a6b5c4-d3e2-4f1a-a0b9-8c2d1e3f4a5b",
          "text": "Monitor memory usage using tools like Node's built-in process.memoryUsage or heap snapshots. Use profiling (e.g., Chrome DevTools or clinic.js) to find objects that aren't released. Fix the leak by ensuring references are cleared and by avoiding global variables that accumulate data.",
          "keyPoints": [
            "Monitor memory usage",
            "Take heap snapshots",
            "Use profiling tools",
            "Identify and release retained objects"
          ]
        }
      ]
    },
    {
      "id": "e2b4f9a2-8d3a-4cce-bb5b-7d2e7a3f1b0a",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "API Versioning Strategies",
      "description": "Explain two different strategies for API versioning in backend systems. What are the advantages and disadvantages of each?",
      "prompt": "Describe at least two approaches to API versioning. For each, list its pros and cons.",
      "topic": "backend",
      "subtopics": [
        "api",
        "versioning",
        "design"
      ],
      "tags": [
        "api",
        "versioning",
        "design",
        "backend"
      ],
      "estimatedTimeMinutes": 13,
      "aiEvaluationHint": "Look for answers mentioning strategies such as URI versioning (/v1/), header-based versioning, or query parameter versioning. Candidates should list at least one advantage and one disadvantage of each method. Penalize if only versioning names are listed with no further detail.",
      "companies": [
        {
          "name": "Oracle",
          "logo": "SiOracle",
          "size": [
            "enterprise"
          ],
          "description": "Cloud applications and platform services."
        }
      ],
      "positions": [
        "backend"
      ],
      "primaryTechStack": [
        "java",
        "spring",
        "python",
        "flask"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid"
      ],
      "createdAt": "2024-06-10T09:55:00Z",
      "updatedAt": "2024-06-10T09:55:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "a2c3e4f5-6b7d-8e9f-0a1b-2c3d4e5f6a7b",
          "text": "URI versioning (e.g., /api/v1/resource) is simple and clear, but can lead to duplicated code. Header-based versioning keeps URLs clean but is less transparent and harder for clients to understand. Both methods have trade-offs between simplicity and flexibility.",
          "keyPoints": [
            "URI versioning with pros/cons",
            "Header-based versioning with pros/cons"
          ]
        }
      ]
    },
    {
      "id": "a4e2d709-4e0a-4c89-8e5f-5e5a7c8e1d2b",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Designing a Rate Limiting Solution",
      "description": "Imagine your backend API is experiencing high traffic, including abusive requests from some users. Describe how you would implement rate limiting to protect your service. What factors would you consider when choosing a rate limiting strategy?",
      "prompt": "Explain how to design and implement rate limiting for a backend API. What options exist, and what factors (e.g., fairness, implementation complexity) would you consider when selecting a strategy?",
      "topic": "backend",
      "subtopics": [
        "api",
        "security",
        "rate-limiting"
      ],
      "tags": [
        "rate-limiting",
        "security",
        "api",
        "backend"
      ],
      "estimatedTimeMinutes": 15,
      "aiEvaluationHint": "A good answer should mention techniques like fixed window, sliding window, and token bucket. Considerations should include fairness, burst handling, implementation complexity, and user experience. Award partial credit for mentioning basic rate limiting but full credit requires discussion of trade-offs.",
      "companies": [
        {
          "name": "Google",
          "logo": "SiGoogle",
          "size": [
            "faang"
          ],
          "description": "Global technology company specializing in Internet-related services."
        }
      ],
      "positions": [
        "backend"
      ],
      "primaryTechStack": [
        "nodejs",
        "redis",
        "google-cloud"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher",
        "competitive"
      ],
      "seniorityLevels": [
        "mid"
      ],
      "createdAt": "2024-06-10T10:00:00Z",
      "updatedAt": "2024-06-10T10:00:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "f1e2d3c4-b5a6-47e8-a9b0-c1d2e3f4a5b6",
          "text": "Implement rate limiting using a token bucket or sliding window algorithm. Use a store like Redis to track requests per user. Consider factors like fairness (preventing bursts), ease of implementation, and impact on legitimate users.",
          "keyPoints": [
            "Token bucket/sliding window algorithms",
            "Tracking per-user or per-IP requests",
            "Fairness and implementation trade-offs"
          ]
        }
      ]
    },
    {
      "id": "e8f1b7a2-6c3e-4f5d-9e2a-1b4d0c3f2e1b",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "senior",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Resolving Data Consistency in Distributed Systems",
      "description": "Your backend system uses multiple microservices and distributed databases across different regions. Describe a strategy to handle data consistency for user account updates, and discuss the trade-offs involved in your approach.",
      "prompt": "Explain your approach to ensuring consistent user account updates across microservices and distributed databases in different regions. Discuss potential trade-offs such as latency, availability, and complexity.",
      "topic": "backend",
      "subtopics": [
        "distributed-systems",
        "consistency",
        "microservices"
      ],
      "tags": [
        "distributed-systems",
        "consistency",
        "microservices",
        "backend"
      ],
      "estimatedTimeMinutes": 20,
      "aiEvaluationHint": "Look for a strategy such as eventual consistency, distributed transactions, or the use of event-driven architectures. The answer should discuss trade-offs like increased complexity, possible stale reads, higher latency, or reduced availability. Penalize for ignoring the trade-offs.",
      "companies": [
        {
          "name": "Microsoft Azure",
          "logo": "SiMicrosoftazure",
          "size": [
            "faang"
          ],
          "description": "Cloud computing platform and services."
        }
      ],
      "positions": [
        "backend"
      ],
      "primaryTechStack": [
        "azure",
        "dotnet",
        "cosmosdb"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher",
        "competitive"
      ],
      "seniorityLevels": [
        "senior"
      ],
      "createdAt": "2024-06-10T10:05:00Z",
      "updatedAt": "2024-06-10T10:05:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "a3b2c1d0-e4f5-47a8-9c2d-5e6f7a8b9c0d",
          "text": "Use eventual consistency and event-driven communication (e.g., via message queues) to propagate user updates. This increases system availability and scalability but can lead to temporary inconsistencies and added complexity. Strong consistency can be enforced with distributed transactions, but at the cost of higher latency and reduced availability.",
          "keyPoints": [
            "Eventual consistency/event-driven architecture",
            "Trade-offs: availability, latency, complexity, possible stale reads",
            "Alternative: distributed transactions"
          ]
        }
      ]
    },
    {
      "id": "4eacb4e9-6c5a-4a16-8e3d-8f5e7d42b23a",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "startup",
      "title": "Explain the role of REST APIs in a fullstack web application",
      "description": "Describe how REST APIs enable communication between the frontend and backend in a typical fullstack web application. Include why they are useful and what makes them a good choice for many projects.",
      "prompt": "Explain how REST APIs are commonly used to connect frontend and backend components in a fullstack web application. Cover their basic principles, advantages, and why they are commonly chosen.",
      "topic": "fullstack",
      "subtopics": [
        "api",
        "backend",
        "frontend",
        "http"
      ],
      "tags": [
        "rest",
        "api",
        "http",
        "architecture",
        "fullstack"
      ],
      "estimatedTimeMinutes": 7,
      "aiEvaluationHint": "A strong answer should explain that REST APIs provide a standardized way for the frontend to communicate with the backend using HTTP methods (GET, POST, etc.), usually exchanging JSON data. The answer should mention benefits: decoupling frontend and backend, scalability, and ease of integration with various clients. Penalize answers that only mention 'fetch data' without explaining HTTP or decoupling. Partial credit for mentioning API use without covering REST-specific aspects.",
      "companies": [
        {
          "name": "Airbnb",
          "logo": "SiAirbnb",
          "size": [
            "startup"
          ],
          "description": "A leading online marketplace for lodging and tourism experiences."
        }
      ],
      "positions": [
        "fullstack"
      ],
      "primaryTechStack": [
        "nodejs",
        "react"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-11T10:00:00Z",
      "updatedAt": "2024-06-11T10:00:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "7b6b4a08-5baf-43dd-bd3b-3a8a60ebd0e7",
          "text": "REST APIs allow the frontend and backend of a web application to communicate over HTTP using standardized methods like GET and POST. They enable the frontend to request or send data to the backend, often using JSON. REST APIs make it easy to separate concerns, allowing different teams to work independently on the frontend and backend.",
          "keyPoints": [
            "REST APIs use HTTP methods",
            "Enable frontend-backend communication",
            "Standardized data exchange (e.g., JSON)",
            "Foster decoupling and scalability"
          ]
        }
      ]
    },
    {
      "id": "e3e2b6be-6d4a-4a4e-82d6-0a6b12b0e588",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Describe the difference between client-side and server-side rendering",
      "description": "What is the difference between client-side rendering and server-side rendering in web applications? Provide an example use case for each approach.",
      "prompt": "Explain the fundamental differences between client-side and server-side rendering in web applications. Include at least one use case where each is preferred.",
      "topic": "fullstack",
      "subtopics": [
        "rendering",
        "frontend",
        "backend",
        "performance"
      ],
      "tags": [
        "csr",
        "ssr",
        "rendering",
        "react",
        "fullstack"
      ],
      "estimatedTimeMinutes": 8,
      "aiEvaluationHint": "Expect clear definitions: client-side rendering means the browser builds the page from JavaScript, while server-side rendering means the server sends a fully rendered page. Look for mention of SEO and performance as trade-offs. Penalize answers that confuse which side does the rendering. Partial credit for partial but correct distinctions.",
      "companies": [
        {
          "name": "LinkedIn",
          "logo": "SiLinkedin",
          "size": [
            "enterprise"
          ],
          "description": "A professional networking platform."
        }
      ],
      "positions": [
        "fullstack"
      ],
      "primaryTechStack": [
        "react",
        "nextjs",
        "nodejs"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-11T10:01:00Z",
      "updatedAt": "2024-06-11T10:01:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "bdb81e5c-5e7e-4bcf-9233-e29eb08e4f73",
          "text": "Client-side rendering happens in the browser after the page loads, using JavaScript to display content. Server-side rendering means the server sends a finished HTML page to the client. SSR is better for SEO and initial load performance, while CSR allows for more dynamic user experiences.",
          "keyPoints": [
            "Client-side: browser renders after load",
            "Server-side: server sends finished HTML",
            "SSR better for SEO and first load",
            "CSR better for dynamic apps"
          ]
        }
      ]
    },
    {
      "id": "f8b2e037-60e4-4d5c-bd5d-6a7ae5d5f82a",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "faang",
      "title": "Debugging a CORS error in a fullstack application",
      "description": "You are developing a React frontend and a Node.js backend. When the frontend tries to fetch data from the backend, you get a CORS (Cross-Origin Resource Sharing) error in the browser. Describe why this might happen and how you would resolve it.",
      "prompt": "Given a scenario where a React frontend and Node.js backend are running on different domains or ports and a CORS error appears, explain why this occurs and outline the steps to fix it.",
      "topic": "fullstack",
      "subtopics": [
        "debugging",
        "api",
        "security",
        "http"
      ],
      "tags": [
        "cors",
        "http",
        "debugging",
        "react",
        "nodejs",
        "fullstack"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Look for awareness that CORS errors occur due to the browser blocking requests to a different origin for security. A strong answer should mention configuring CORS headers on the backend (using middleware like 'cors' in Express). Penalize answers that incorrectly suggest fixing only on the frontend or that ignore browser security. Partial credit for identifying the server as the main fix point.",
      "companies": [
        {
          "name": "Netflix",
          "logo": "SiNetflix",
          "size": [
            "faang"
          ],
          "description": "A leading streaming entertainment service."
        }
      ],
      "positions": [
        "fullstack"
      ],
      "primaryTechStack": [
        "react",
        "nodejs",
        "express"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-11T10:02:00Z",
      "updatedAt": "2024-06-11T10:02:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "d5a3d9c3-7d9d-49e1-bc8f-8a3a9a2b5f7c",
          "text": "A CORS error occurs because the browser restricts requests between different origins for security. To fix it, configure the backend to send the correct CORS headers, such as using the 'cors' middleware in Express to allow requests from the frontend's domain.",
          "keyPoints": [
            "CORS errors are browser-enforced for security",
            "Origins differ (domains/ports)",
            "Fix by setting CORS headers on backend",
            "Example: use 'cors' middleware in Express"
          ]
        }
      ]
    },
    {
      "id": "d4b2d1b3-52c6-4b8e-89b6-0037e02f9b79",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "startup",
      "title": "Handling user authentication in a modern fullstack application",
      "description": "Explain the main steps involved in implementing secure user authentication in a fullstack web application. What technologies or protocols are commonly used, and what are best practices to keep user credentials safe?",
      "prompt": "Describe the process of implementing user authentication in a fullstack web app. Include typical technologies/protocols (like JWT, OAuth) and best practices for handling passwords and sessions.",
      "topic": "fullstack",
      "subtopics": [
        "authentication",
        "security",
        "sessions"
      ],
      "tags": [
        "authentication",
        "security",
        "jwt",
        "oauth",
        "fullstack"
      ],
      "estimatedTimeMinutes": 12,
      "aiEvaluationHint": "Expect mention of steps like user registration, password hashing, issuing tokens (JWT), and session management. Strong answers note not storing plaintext passwords, using HTTPS, and possibly OAuth for third-party auth. Penalize answers that suggest storing passwords in plain text or lack security context.",
      "companies": [
        {
          "name": "Stripe",
          "logo": "SiStripe",
          "size": [
            "startup"
          ],
          "description": "A technology company that builds economic infrastructure for the internet."
        }
      ],
      "positions": [
        "fullstack"
      ],
      "primaryTechStack": [
        "nodejs",
        "react",
        "mongodb"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "competitive"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-11T10:03:00Z",
      "updatedAt": "2024-06-11T10:03:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "e7f0a6d9-db2c-4ebd-9f3a-2b6c8e0b7f52",
          "text": "First, users register and passwords are hashed before being stored. On login, the backend verifies the hash and issues a session or JWT token. OAuth can be used for third-party logins. Always use HTTPS and never store passwords in plain text.",
          "keyPoints": [
            "Hash passwords before storing",
            "Use JWT or sessions for authentication",
            "Can use OAuth for external logins",
            "HTTPS required, never store plain text passwords"
          ]
        }
      ]
    },
    {
      "id": "7c6e8b04-6866-4b1b-94b8-bc3e8d43e2e1",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Improving frontend performance by optimizing API calls",
      "description": "Your single-page application makes several API calls every time a user opens the dashboard, causing slow load times. What strategies can you use to improve loading performance and reduce unnecessary network requests?",
      "prompt": "Suggest techniques to optimize frontend performance in a SPA by reducing and optimizing API calls. Consider caching, request deduplication, and data prefetching.",
      "topic": "fullstack",
      "subtopics": [
        "performance",
        "api",
        "frontend"
      ],
      "tags": [
        "performance",
        "api",
        "optimization",
        "frontend",
        "caching"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Look for answers mentioning caching responses, batching or deduplicating requests, lazy loading, and minimizing requests on load. Strong answers could reference tools or libraries (e.g., React Query, SWR). Penalize answers that only suggest 'load less data' without explaining strategies.",
      "companies": [
        {
          "name": "Salesforce",
          "logo": "SiSalesforce",
          "size": [
            "enterprise"
          ],
          "description": "A leading cloud-based CRM and business software provider."
        }
      ],
      "positions": [
        "fullstack"
      ],
      "primaryTechStack": [
        "react",
        "typescript",
        "nodejs"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-11T10:04:00Z",
      "updatedAt": "2024-06-11T10:04:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "c9e6e5fb-17e2-41b7-8f60-2ed6f5b1d9a7",
          "text": "You can cache API responses locally (e.g., in-memory, localStorage, or with React Query), batch multiple requests together, and avoid duplicate requests with debouncing or request deduplication. Also, prefetch data when appropriate and lazy load non-critical data after the initial render.",
          "keyPoints": [
            "Cache API responses",
            "Batch or deduplicate requests",
            "Prefetch or lazy load data",
            "Minimize requests on initial load"
          ]
        }
      ]
    },
    {
      "id": "3ce6b6a2-0a4d-4661-bb62-84e6f0b765c0",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Designing a file upload feature for large files",
      "description": "You need to implement a feature allowing users to upload large files (hundreds of MBs) from the frontend to the backend. What architectural considerations and technical approaches would you use to ensure reliability and good user experience?",
      "prompt": "Describe how you would design a robust file upload feature for large files in a fullstack application. Discuss options like chunked uploads, progress feedback, error handling, and backend processing.",
      "topic": "fullstack",
      "subtopics": [
        "architecture",
        "file-upload",
        "user-experience",
        "backend"
      ],
      "tags": [
        "file-upload",
        "architecture",
        "reliability",
        "frontend",
        "backend"
      ],
      "estimatedTimeMinutes": 15,
      "aiEvaluationHint": "A good answer should mention chunked or multipart uploads, progress bars, retry mechanisms for failed chunks, and backend APIs that can handle large files. Backend may store files in cloud storage. Penalize answers that suggest naive single-request approaches or ignore user feedback. Partial credit for mentioning only chunking or progress.",
      "companies": [
        {
          "name": "Google",
          "logo": "SiGoogle",
          "size": [
            "faang"
          ],
          "description": "A global technology company specializing in search, advertising, and cloud computing."
        }
      ],
      "positions": [
        "fullstack"
      ],
      "primaryTechStack": [
        "react",
        "nodejs",
        "aws"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "competitive"
      ],
      "seniorityLevels": [
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-11T10:05:00Z",
      "updatedAt": "2024-06-11T10:05:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "c7183a8d-1c8d-4a6b-ae98-1f2beae6f3a2",
          "text": "Use chunked uploads to split large files into smaller parts, upload each part separately, and allow retries for failed chunks. Show users upload progress, and process files asynchronously on the backend. Store files in cloud storage like S3 for scalability and reliability.",
          "keyPoints": [
            "Chunked/multipart uploads",
            "Progress feedback to users",
            "Retry failed uploads",
            "Backend integration with cloud storage"
          ]
        }
      ]
    },
    {
      "id": "9f6e7b1c-5fd6-4ef2-8f38-19d7afc1e1b3",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Maintaining consistency between frontend and backend validation",
      "description": "How do you ensure that form validation rules are consistent between the frontend and backend in a fullstack application? Why is this important, and what techniques can help avoid duplication and errors?",
      "prompt": "Explain strategies for keeping frontend and backend form validation consistent in a fullstack application. Discuss the importance and possible tools or patterns to reduce code duplication.",
      "topic": "fullstack",
      "subtopics": [
        "validation",
        "form",
        "frontend",
        "backend"
      ],
      "tags": [
        "validation",
        "form",
        "frontend",
        "backend",
        "consistency"
      ],
      "estimatedTimeMinutes": 12,
      "aiEvaluationHint": "Look for answers mentioning shared validation logic or schemas (e.g., using libraries like Joi, Yup, or JSON Schema), and why double validation is important: security and user experience. Penalize answers that suggest only validating on the frontend or don't address duplication. Credit for mentioning DRY principles or schema sharing.",
      "companies": [
        {
          "name": "SAP",
          "logo": "SiSap",
          "size": [
            "enterprise"
          ],
          "description": "A multinational software company known for enterprise solutions."
        }
      ],
      "positions": [
        "fullstack"
      ],
      "primaryTechStack": [
        "typescript",
        "nodejs",
        "react"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-11T10:06:00Z",
      "updatedAt": "2024-06-11T10:06:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "f6e2d3a1-5a0c-4f7e-ae69-84a5b4c9c32b",
          "text": "Use a shared schema (e.g., with libraries like Yup or JSON Schema) so that both frontend and backend use the same validation logic. This avoids duplication and ensures consistent error messages and security. Validating on both sides prevents malicious input from bypassing rules.",
          "keyPoints": [
            "Shared validation schema",
            "Avoid code duplication",
            "Security and UX reasons for double validation",
            "Examples: Yup, Joi, JSON Schema"
          ]
        }
      ]
    },
    {
      "id": "c3d6f672-cd91-429e-bf98-8f7d3c0e3b8a",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "startup",
      "title": "Implementing real-time features in a chat application",
      "description": "You are tasked with adding real-time chat functionality to an existing fullstack application. What technologies and architectural changes would you consider, and how would you ensure reliability and scalability?",
      "prompt": "Explain how you would implement real-time chat in a fullstack application. Cover technology choices (e.g., WebSockets), backend changes, and methods to scale and maintain reliability under high load.",
      "topic": "fullstack",
      "subtopics": [
        "real-time",
        "chat",
        "websockets",
        "scalability"
      ],
      "tags": [
        "real-time",
        "websockets",
        "chat",
        "scalability",
        "fullstack"
      ],
      "estimatedTimeMinutes": 16,
      "aiEvaluationHint": "Expect mention of WebSockets or a real-time protocol, backend support (like socket.io), message persistence, and strategies for scaling (load balancing, pub/sub, managed services). Penalize answers that only mention polling or ignore scaling. Partial credit for discussing technology without architectural reasoning.",
      "companies": [
        {
          "name": "Snapchat",
          "logo": "SiSnapchat",
          "size": [
            "startup"
          ],
          "description": "A social media platform focused on multimedia messaging."
        }
      ],
      "positions": [
        "fullstack"
      ],
      "primaryTechStack": [
        "nodejs",
        "react",
        "socket.io"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "competitive"
      ],
      "seniorityLevels": [
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-11T10:07:00Z",
      "updatedAt": "2024-06-11T10:07:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "b2a33c6d-0a7a-4eb2-91c4-1eab6b6f0b8a",
          "text": "Use WebSockets (e.g., with socket.io) to enable real-time communication. Backend changes include managing socket connections and persisting messages. For scalability, use a pub/sub system (like Redis) and consider managed WebSocket services to handle large numbers of users reliably.",
          "keyPoints": [
            "Use WebSockets/socket.io",
            "Backend manages connections and message persistence",
            "Pub/sub or managed services for scaling",
            "Reliability via load balancing"
          ]
        }
      ]
    },
    {
      "id": "a4d8b6b0-7e7e-4d9c-b6c0-4e9a2b0d4e8d",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "senior",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Diagnosing and resolving a production memory leak in a Node.js fullstack app",
      "description": "A Node.js backend serving a popular React-based web app is experiencing increasing memory usage and occasional crashes in production. Walk through how you would diagnose and fix a memory leak in this fullstack context, mentioning tools, processes, and communication.",
      "prompt": "Describe a systematic approach to identifying, debugging, and fixing a memory leak in a Node.js backend that supports a React frontend. Include tools for profiling, code review, and how you would coordinate with your team to minimize downtime.",
      "topic": "fullstack",
      "subtopics": [
        "debugging",
        "performance",
        "memory-leak",
        "nodejs"
      ],
      "tags": [
        "debugging",
        "memory",
        "nodejs",
        "production",
        "fullstack"
      ],
      "estimatedTimeMinutes": 20,
      "aiEvaluationHint": "A strong answer should mention monitoring memory usage over time, using tools like heap snapshots, Node.js inspectors, and logs. The answer should describe reviewing recent code changes, reproducing the leak, identifying the root cause (e.g., unclosed connections, large in-memory objects), and deploying staged fixes. Coordination with ops/QA for safe rollouts is important. Penalize answers that are vague or skip systematic steps.",
      "companies": [
        {
          "name": "Meta",
          "logo": "SiMeta",
          "size": [
            "faang"
          ],
          "description": "A leading social technology company."
        }
      ],
      "positions": [
        "fullstack"
      ],
      "primaryTechStack": [
        "nodejs",
        "react"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "senior"
      ],
      "createdAt": "2024-06-11T10:08:00Z",
      "updatedAt": "2024-06-11T10:08:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "f4d3f5b7-85a6-4df1-ae84-1c9b6d1a0f4e",
          "text": "Monitor memory usage in production, use tools like Node.js heapdump or Chrome DevTools for heap snapshots, and analyze them to find leaks. Review recent code changes for unclosed resources. Reproduce the issue locally, fix the leak, and deploy gradually. Communicate with ops and QA to monitor after release.",
          "keyPoints": [
            "Monitor memory over time",
            "Heap snapshots and profiling tools",
            "Review code for leaks (e.g., unclosed connections)",
            "Reproduce, fix, and deploy with coordination"
          ]
        }
      ]
    },
    {
      "id": "6c7d6c6a-1a3e-4c4c-8b9d-2d8e1b3e9c7a",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Implementing role-based access control (RBAC) in a fullstack application",
      "description": "How would you design and implement role-based access control in a fullstack web app to ensure users have appropriate permissions for different actions? Give an example of how roles might be checked both on the frontend and backend.",
      "prompt": "Describe the architecture and implementation of RBAC in a fullstack app. Include strategies for managing roles and permissions, and show how you would enforce checks both in the frontend and backend.",
      "topic": "fullstack",
      "subtopics": [
        "security",
        "rbac",
        "authorization"
      ],
      "tags": [
        "rbac",
        "authorization",
        "security",
        "fullstack"
      ],
      "estimatedTimeMinutes": 13,
      "aiEvaluationHint": "Expect mention of defining roles and permissions, backend enforcement (e.g., middleware checking user roles), and frontend checks to enable/disable UI elements. Strong answers stress that backend checks are required for security. Partial credit for describing only frontend or backend enforcement.",
      "companies": [
        {
          "name": "IBM",
          "logo": "SiIbm",
          "size": [
            "enterprise"
          ],
          "description": "A multinational technology and consulting company."
        }
      ],
      "positions": [
        "fullstack"
      ],
      "primaryTechStack": [
        "nodejs",
        "react",
        "mongodb"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-11T10:09:00Z",
      "updatedAt": "2024-06-11T10:09:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "b9f1a6d2-1f2e-4e5d-b8d2-7e6b9f3d0a8b",
          "text": "Define user roles and permissions in your database. On the backend, use middleware to check a user's role before allowing access to protected routes. On the frontend, hide or disable UI elements based on the user's role, but always enforce access in the backend for security.",
          "keyPoints": [
            "Define roles/permissions in DB",
            "Backend middleware for authorization",
            "Frontend UI adapts to role",
            "Security requires backend enforcement"
          ]
        }
      ]
    },
    {
      "id": "f2b8e1b6-7e2e-4e8d-8b6c-4d8b9e7a2f1a",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "startup",
      "title": "Integrating third-party APIs in a fullstack application",
      "description": "Your product team asks you to show live weather data on your application's dashboard. Explain how you would integrate a third-party weather API in your fullstack application and handle potential errors or latency issues.",
      "prompt": "Describe the steps for integrating a third-party weather API into a fullstack application. Cover backend requests, caching, error handling, and how to ensure the frontend handles delays or failures gracefully.",
      "topic": "fullstack",
      "subtopics": [
        "api",
        "integration",
        "error-handling"
      ],
      "tags": [
        "api",
        "third-party",
        "integration",
        "error-handling",
        "fullstack"
      ],
      "estimatedTimeMinutes": 11,
      "aiEvaluationHint": "A complete answer should mention making API calls from the backend (to hide API keys), caching responses to handle rate limits/latency, and returning friendly errors to the frontend. The frontend should show loading or fallback states if the API is slow or unavailable. Penalize answers that just call the API from the frontend or ignore error handling.",
      "companies": [
        {
          "name": "Vercel",
          "logo": "SiVercel",
          "size": [
            "startup"
          ],
          "description": "A cloud platform for frontend developers, providing hosting and serverless functions."
        }
      ],
      "positions": [
        "fullstack"
      ],
      "primaryTechStack": [
        "nodejs",
        "react"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-11T10:10:00Z",
      "updatedAt": "2024-06-11T10:10:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "a1c6b0e6-8b7e-4e8d-9a6b-7d2e8a1b6f4c",
          "text": "Call the weather API from the backend to protect the API key, cache the responses to reduce latency and API usage, and handle errors by sending fallback data or messages. The frontend should display a loading spinner and show a friendly message if data is unavailable.",
          "keyPoints": [
            "Backend integration for security",
            "Caching API responses",
            "Graceful error handling",
            "Frontend handles delays/failures gracefully"
          ]
        }
      ]
    },
    {
      "id": "7f9f7f3f-902e-4d1e-82e1-1f9e9b2c0a11",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Explaining the Benefits of Infrastructure as Code",
      "description": "Describe the main advantages of using Infrastructure as Code (IaC) in a DevOps workflow. Explain how IaC impacts collaboration and deployment speed.",
      "prompt": "Explain the key benefits that Infrastructure as Code (IaC) brings to a DevOps environment. Discuss how it improves collaboration among teams and affects deployment speed.",
      "topic": "devops",
      "subtopics": [
        "infrastructure-as-code",
        "automation",
        "collaboration"
      ],
      "tags": [
        "iac",
        "automation",
        "devops",
        "terraform"
      ],
      "estimatedTimeMinutes": 7,
      "aiEvaluationHint": "Look for mentions of automation, repeatability, version control, reduced manual errors, and faster deployments. Strong answers will explain how IaC enables better collaboration through code review and shared repositories. Partial credit if only some benefits are listed.",
      "companies": [
        {
          "name": "Amazon AWS",
          "logo": "SiAmazonaws",
          "size": [
            "enterprise"
          ],
          "description": "Leading cloud services provider known for scalable infrastructure and DevOps tooling."
        }
      ],
      "positions": [
        "devops"
      ],
      "primaryTechStack": [
        "terraform",
        "ansible"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-01T09:00:00Z",
      "updatedAt": "2024-06-01T09:00:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "8c5a2b77-31a7-4d55-98fb-3e2e49f4cf45",
          "text": "IaC allows teams to define infrastructure as code, making it possible to automate the provisioning and management of resources. This reduces manual errors, increases deployment speed, and enables teams to collaborate using familiar code review and version control practices.",
          "keyPoints": [
            "Automation and repeatability",
            "Version control and collaboration",
            "Reduced manual errors",
            "Faster and more reliable deployments"
          ]
        }
      ]
    },
    {
      "id": "2e3f8a26-4c79-47d1-8995-4c5e155db9a3",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "startup",
      "title": "Identifying the Purpose of Continuous Integration",
      "description": "What is the primary goal of Continuous Integration (CI) in a DevOps workflow, and how does it benefit software development teams?",
      "prompt": "Explain the main purpose of Continuous Integration in DevOps. Describe how it helps developers and teams deliver better software.",
      "topic": "devops",
      "subtopics": [
        "continuous-integration",
        "automation"
      ],
      "tags": [
        "ci",
        "build",
        "devops",
        "testing"
      ],
      "estimatedTimeMinutes": 5,
      "aiEvaluationHint": "Expect answers that mention frequent code integration, automated builds and tests, early bug detection, and improved team collaboration. Award full credit if the answer connects CI to faster, higher-quality releases.",
      "companies": [
        {
          "name": "Vercel",
          "logo": "SiVercel",
          "size": [
            "startup"
          ],
          "description": "Modern cloud platform focused on frontend and DevOps workflows."
        }
      ],
      "positions": [
        "devops"
      ],
      "primaryTechStack": [
        "github-actions",
        "jenkins"
      ],
      "interviewTypes": [
        "practice",
        "flash",
        "teacher"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-01T09:01:00Z",
      "updatedAt": "2024-06-01T09:01:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "cafdb34e-4c48-4f4a-8c05-6b17e1b7b7fa",
          "text": "Continuous Integration ensures that code changes are integrated and tested frequently. This detects bugs early, prevents integration issues, and allows teams to release updates more confidently and quickly.",
          "keyPoints": [
            "Frequent code integration",
            "Automated build and testing",
            "Early bug detection",
            "Faster, more reliable releases"
          ]
        }
      ]
    },
    {
      "id": "da5a01b2-20c2-4fab-9e6c-e2cb8d1e7e8d",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "faang",
      "title": "Debugging a Failing Deployment Pipeline",
      "description": "A deployment pipeline fails at the 'integration tests' stage, even though the build and unit tests passed. As a DevOps engineer, how would you approach debugging this issue?",
      "prompt": "Describe your step-by-step process for diagnosing and resolving a scenario where a deployment pipeline fails at the integration test stage, but earlier steps succeed.",
      "topic": "devops",
      "subtopics": [
        "cicd",
        "testing",
        "debugging"
      ],
      "tags": [
        "ci",
        "integration-testing",
        "pipeline",
        "troubleshooting"
      ],
      "estimatedTimeMinutes": 12,
      "aiEvaluationHint": "The answer should cover checking integration test logs, environment differences, database or external service dependencies, and recent changes. Full credit for clear, logical diagnostic steps. Partial credit if only generic debugging is mentioned.",
      "companies": [
        {
          "name": "Netflix",
          "logo": "SiNetflix",
          "size": [
            "faang"
          ],
          "description": "Streaming platform with advanced DevOps and automation practices."
        }
      ],
      "positions": [
        "devops"
      ],
      "primaryTechStack": [
        "jenkins",
        "docker"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "competitive"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-01T09:02:00Z",
      "updatedAt": "2024-06-01T09:02:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "b6d2d27e-7e0f-4e2f-8a2e-6c7f9b8f7b6c",
          "text": "First, review the integration test logs for errors or stack traces. Check if environment variables, databases, or external services are configured correctly in the test environment. Investigate recent code or configuration changes that might affect integration. Re-run tests locally if possible to reproduce the issue.",
          "keyPoints": [
            "Analyze test log output",
            "Check environment and configuration",
            "Review dependencies (databases, services)",
            "Investigate recent changes"
          ]
        }
      ]
    },
    {
      "id": "a8d2c01e-8b43-471a-bb9c-4a2b8f7d7c2c",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Choosing Between Containers and Virtual Machines",
      "description": "Explain when you would recommend using containers over virtual machines in a deployment architecture. What key factors should be considered?",
      "prompt": "Describe scenarios where containers are preferable to virtual machines in deployment. List the main considerations influencing your recommendation.",
      "topic": "devops",
      "subtopics": [
        "containers",
        "virtualization",
        "architecture"
      ],
      "tags": [
        "docker",
        "kubernetes",
        "vm",
        "architecture"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Expect explanations about lightweight resource usage, faster startup, isolation, and scalability. Strong answers compare both technologies and discuss security, overhead, and use cases. Award partial credit for incomplete comparisons.",
      "companies": [
        {
          "name": "Google Cloud",
          "logo": "SiGooglecloud",
          "size": [
            "enterprise"
          ],
          "description": "Cloud provider with strong container orchestration and DevOps tools."
        }
      ],
      "positions": [
        "devops"
      ],
      "primaryTechStack": [
        "docker",
        "kubernetes"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-01T09:03:00Z",
      "updatedAt": "2024-06-01T09:03:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "0c3a88a9-8b7a-4e3d-9c5a-5c6b4c2c3a9b",
          "text": "Containers are ideal when you need lightweight, fast-starting, and easily scalable environments. Use them for microservices, CI/CD pipelines, or when high resource efficiency is needed. VMs are better for full OS isolation, legacy workloads, or when stronger security boundaries are required.",
          "keyPoints": [
            "Containers: lightweight, fast, scalable",
            "VMs: full OS isolation, legacy, strong security",
            "Consider resource usage, speed, and security"
          ]
        }
      ]
    },
    {
      "id": "c8b1e7e9-3975-4b56-932c-0b2e9c8f2e3c",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "startup",
      "title": "Responding to a Sudden Traffic Spike",
      "description": "Your application experiences a sudden spike in user traffic, causing slower response times. As a DevOps engineer, what immediate steps would you take to restore performance?",
      "prompt": "Describe your approach to quickly restoring application performance after an unexpected spike in user traffic. List the actions you would prioritize.",
      "topic": "devops",
      "subtopics": [
        "monitoring",
        "scaling",
        "incident-response"
      ],
      "tags": [
        "autoscaling",
        "cloud",
        "performance",
        "monitoring"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Look for answers that mention monitoring, identifying bottlenecks, scaling up resources, and communicating with stakeholders. Full credit for a clear, prioritized action plan. Penalize if the answer misses immediate monitoring or scaling.",
      "companies": [
        {
          "name": "Cloudflare",
          "logo": "SiCloudflare",
          "size": [
            "startup"
          ],
          "description": "Internet infrastructure and security company with a focus on scalability."
        }
      ],
      "positions": [
        "devops"
      ],
      "primaryTechStack": [
        "aws",
        "kubernetes",
        "prometheus"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "competitive"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-01T09:04:00Z",
      "updatedAt": "2024-06-01T09:04:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "e0bc0c3b-8a05-42b9-bcdd-6d6d0e2e7f11",
          "text": "First, monitor current metrics to identify which resources are saturated (CPU, memory, network). Scale up application instances or enable autoscaling. Offload traffic if possible using CDNs or caching. Communicate status and mitigation steps to the team.",
          "keyPoints": [
            "Check monitoring metrics",
            "Scale up resources/autoscaling",
            "Use caching/CDN if possible",
            "Communicate with stakeholders"
          ]
        }
      ]
    },
    {
      "id": "e7d6ae94-2b7d-4a8d-889c-69e6b438b9c9",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Implementing Blue-Green Deployment Safely",
      "description": "Describe how you would implement a blue-green deployment strategy for a web application to minimize downtime and risk. What steps are essential to ensure a successful rollout?",
      "prompt": "Explain your process for setting up and executing a blue-green deployment for a web application. List key steps that help minimize downtime and mitigate deployment risk.",
      "topic": "devops",
      "subtopics": [
        "deployment-strategies",
        "zero-downtime",
        "release-management"
      ],
      "tags": [
        "blue-green",
        "deployment",
        "risk-mitigation",
        "downtime"
      ],
      "estimatedTimeMinutes": 15,
      "aiEvaluationHint": "Look for a clear explanation of blue and green environments, traffic switching, validation/testing, and rollback processes. Full credit for mentioning verification before cutover and quick rollback. Partial credit if steps are missing or ordering is unclear.",
      "companies": [
        {
          "name": "Microsoft Azure",
          "logo": "SiMicrosoftazure",
          "size": [
            "faang"
          ],
          "description": "Major cloud provider supporting advanced deployment strategies."
        }
      ],
      "positions": [
        "devops"
      ],
      "primaryTechStack": [
        "azure",
        "nginx",
        "docker"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-01T09:05:00Z",
      "updatedAt": "2024-06-01T09:05:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "7a5e3c4e-5c8f-4bf2-9e8a-1ed2a62a2b2f",
          "text": "Create two identical environments (blue and green). Deploy the new version to the green environment, test thoroughly, and only switch production traffic when validation is complete. Monitor for issues and prepare for instant rollback by reverting traffic if necessary.",
          "keyPoints": [
            "Two identical (blue/green) environments",
            "Deploy and test in green",
            "Switch traffic after validation",
            "Monitor and enable quick rollback"
          ]
        }
      ]
    },
    {
      "id": "d3b9b4ae-2a23-4e68-9fba-65b9b3e6bda7",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Securing Secrets in CI/CD Pipelines",
      "description": "How would you securely manage sensitive secrets (e.g., API keys, credentials) in a CI/CD pipeline for a cloud-hosted application?",
      "prompt": "Describe your approach to storing, accessing, and rotating sensitive secrets in a CI/CD pipeline. Address both security and usability concerns.",
      "topic": "devops",
      "subtopics": [
        "security",
        "secrets-management",
        "cicd"
      ],
      "tags": [
        "secrets",
        "cicd",
        "security",
        "cloud"
      ],
      "estimatedTimeMinutes": 13,
      "aiEvaluationHint": "Look for the use of secret managers or encrypted storage, restricted access, avoiding secrets in code or logs, and regular rotation. Full credit for a holistic strategy. Partial credit if only storage or only access is discussed.",
      "companies": [
        {
          "name": "Stripe",
          "logo": "SiStripe",
          "size": [
            "enterprise"
          ],
          "description": "Fintech company with stringent security requirements for deployments."
        }
      ],
      "positions": [
        "devops"
      ],
      "primaryTechStack": [
        "aws",
        "vault",
        "github-actions"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-01T09:06:00Z",
      "updatedAt": "2024-06-01T09:06:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "b9d4e8af-5e19-4e4a-8889-6a2a5b8c1c7c",
          "text": "Store secrets in a secure secrets manager (like AWS Secrets Manager or HashiCorp Vault). Grant access to pipeline agents only as needed. Never commit secrets to code or logs, and rotate them regularly. Use environment variables to inject secrets at runtime.",
          "keyPoints": [
            "Use secrets manager or encrypted storage",
            "Restrict pipeline access to secrets",
            "Never expose secrets in code/logs",
            "Regular secret rotation",
            "Inject at runtime via environment variables"
          ]
        }
      ]
    },
    {
      "id": "f7e0c05d-3c7d-4e62-8c74-d7a4e7e1e4a2",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Improving CI/CD Pipeline Efficiency",
      "description": "A CI/CD pipeline for a large microservices application is running slowly and delaying releases. What strategies would you use to optimize its performance?",
      "prompt": "List and explain methods for making a CI/CD pipeline more efficient for a complex, multi-service application.",
      "topic": "devops",
      "subtopics": [
        "cicd",
        "performance",
        "microservices"
      ],
      "tags": [
        "pipeline",
        "efficiency",
        "microservices",
        "ci"
      ],
      "estimatedTimeMinutes": 15,
      "aiEvaluationHint": "Look for parallelization, caching, change-based builds, splitting pipelines, and resource optimization. Full credit for multiple actionable strategies. Penalize for vague or generic suggestions.",
      "companies": [
        {
          "name": "Uber",
          "logo": "SiUber",
          "size": [
            "faang"
          ],
          "description": "Large-scale microservices platform with demanding CI/CD needs."
        }
      ],
      "positions": [
        "devops"
      ],
      "primaryTechStack": [
        "jenkins",
        "docker",
        "kubernetes"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "competitive"
      ],
      "seniorityLevels": [
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-01T09:07:00Z",
      "updatedAt": "2024-06-01T09:07:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "e4fe5e8e-6b1c-4b93-9b11-7b9c2d3a5c0e",
          "text": "Parallelize jobs where possible, use build/test caching, and only run builds/tests for changed services. Break the pipeline into smaller, service-specific jobs. Optimize resource allocation and monitor for bottlenecks.",
          "keyPoints": [
            "Parallelization",
            "Caching builds and dependencies",
            "Change-based builds/tests",
            "Splitting pipeline by service",
            "Monitoring and resource optimization"
          ]
        }
      ]
    },
    {
      "id": "1e5f1e8e-8c4b-4a1c-b2a8-8c6c1e0b3c1f",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "senior",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Diagnosing Intermittent Production Outages",
      "description": "A mission-critical distributed application is experiencing intermittent outages in production. Outline your approach to diagnose and resolve the underlying issues, considering both infrastructure and application-level factors.",
      "prompt": "Describe your step-by-step methodology for identifying and resolving intermittent outages affecting a distributed production system. Include both infrastructure and application considerations.",
      "topic": "devops",
      "subtopics": [
        "incident-response",
        "observability",
        "distributed-systems",
        "troubleshooting"
      ],
      "tags": [
        "outage",
        "debugging",
        "observability",
        "production"
      ],
      "estimatedTimeMinutes": 20,
      "aiEvaluationHint": "Expect a structured approach: collect logs/metrics, correlate symptoms, check for resource exhaustion, network issues, and application-level patterns. Full credit for discussing observability, hypothesis-driven investigation, and clear remediation. Penalize if only basic debugging is mentioned.",
      "companies": [
        {
          "name": "Google",
          "logo": "SiGoogle",
          "size": [
            "faang"
          ],
          "description": "Global technology leader with large-scale distributed systems."
        }
      ],
      "positions": [
        "devops"
      ],
      "primaryTechStack": [
        "gcp",
        "prometheus",
        "grafana",
        "kubernetes"
      ],
      "interviewTypes": [
        "regular",
        "competitive",
        "teacher"
      ],
      "seniorityLevels": [
        "senior"
      ],
      "createdAt": "2024-06-01T09:08:00Z",
      "updatedAt": "2024-06-01T09:08:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "d7a1b0b6-1c2e-4d6c-9a4c-7e8d5b2a1e0a",
          "text": "Start by collecting logs, metrics, and traces from all affected components. Look for patterns in timing, involved nodes, and error messages. Check for resource exhaustion, network partitions, or external dependency failures. Use correlation to form hypotheses, test them, and remediate the root cause. Document findings and implement monitoring to prevent recurrence.",
          "keyPoints": [
            "Comprehensive observability (logs, metrics, tracing)",
            "Pattern analysis and correlation",
            "Check infrastructure (resources, network) and application factors",
            "Hypothesis-driven troubleshooting",
            "Remediation and preventive monitoring"
          ]
        }
      ]
    },
    {
      "id": "5bcb7b55-9b5d-4b6c-93e6-5b7c2b4e8c6e",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Ensuring Compliance in Automated Deployments",
      "description": "How can you ensure that automated deployments in a regulated industry (e.g., finance, healthcare) remain compliant with relevant policies and standards?",
      "prompt": "Describe your approach to maintaining policy and regulatory compliance when automating deployments in a highly regulated environment.",
      "topic": "devops",
      "subtopics": [
        "compliance",
        "automation",
        "deployment"
      ],
      "tags": [
        "compliance",
        "audit",
        "policy",
        "automation"
      ],
      "estimatedTimeMinutes": 13,
      "aiEvaluationHint": "Look for use of automated compliance checks, audit logging, policy-as-code, and access controls. Strong answers mention integrating compliance into CI/CD, not just manual reviews. Award partial credit for mentioning only documentation or after-the-fact audits.",
      "companies": [
        {
          "name": "IBM",
          "logo": "SiIbm",
          "size": [
            "enterprise"
          ],
          "description": "Technology provider with extensive experience in regulated industries."
        }
      ],
      "positions": [
        "devops"
      ],
      "primaryTechStack": [
        "terraform",
        "aws",
        "opa"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-01T09:09:00Z",
      "updatedAt": "2024-06-01T09:09:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "a7c1b9e5-4e6d-4e0b-a4a2-9b9a1f2c3b4f",
          "text": "Automate compliance checks using tools like policy-as-code (e.g., OPA). Maintain detailed audit logs of deployments and restrict access through RBAC. Integrate compliance validation into CI/CD pipelines so that non-compliant changes are blocked before deployment.",
          "keyPoints": [
            "Automated compliance checks",
            "Policy-as-code",
            "Audit logging",
            "Access control (RBAC)",
            "CI/CD integration"
          ]
        }
      ]
    },
    {
      "id": "a1e0b7e1-1f63-4e3a-8d3f-9b1be10e2e11",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Explaining MVC in Mobile App Development",
      "description": "Briefly explain the Model-View-Controller (MVC) pattern and how it applies to mobile app development.",
      "prompt": "Describe the Model-View-Controller architectural pattern and specifically explain how it is used in building mobile applications.",
      "topic": "mobile",
      "subtopics": [
        "architecture",
        "mvc",
        "fundamentals"
      ],
      "tags": [
        "architecture",
        "mvc",
        "mobile development",
        "patterns"
      ],
      "estimatedTimeMinutes": 6,
      "aiEvaluationHint": "A full answer should define MVC, clarify what each component does (Model, View, Controller), and explain how this pattern helps organize code in a mobile app context. Partial credit if only the roles are named without description. Penalize confusing MVC with other patterns or omitting the mobile-specific application.",
      "companies": null,
      "positions": [
        "mobile"
      ],
      "primaryTechStack": [
        "swift",
        "kotlin",
        "react-native"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-20T09:00:00Z",
      "updatedAt": "2024-06-20T09:00:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "d7c1e19a-5ba0-4d09-bb3d-4f57df3d5a0e",
          "text": "MVC divides a mobile app into Model (data and logic), View (UI), and Controller (handles interactions and updates model/view). In iOS, ViewControllers act as the controller. This separation helps keep code organized and maintainable.",
          "keyPoints": [
            "Defines Model, View, Controller roles",
            "Explains separation of concerns",
            "Mentions application in mobile context"
          ]
        }
      ]
    },
    {
      "id": "2d7f0a4e-6e4a-4c1f-b0e4-c3e8c83283db",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "startup",
      "title": "Handling Button Tap Events in React Native",
      "description": "Describe how you would handle a button tap event in a React Native mobile application.",
      "prompt": "Explain the process of capturing and responding to a button tap event in a React Native app. Include relevant code or pseudocode as appropriate.",
      "topic": "mobile",
      "subtopics": [
        "react-native",
        "event handling"
      ],
      "tags": [
        "react-native",
        "events",
        "ui",
        "entry-level"
      ],
      "estimatedTimeMinutes": 5,
      "aiEvaluationHint": "Look for mention of React Native's Button or Touchable components, handling the 'onPress' event, and implementing a callback function. Award full credit for clear explanation with code or pseudocode. Partial credit for only naming the event without describing the process.",
      "companies": null,
      "positions": [
        "mobile",
        "frontend"
      ],
      "primaryTechStack": [
        "react-native",
        "javascript"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "flash"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-20T09:01:00Z",
      "updatedAt": "2024-06-20T09:01:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "f2c1a2a6-1b3e-42a2-9a6e-ff7f1d0d4cbe",
          "text": "In React Native, you use the Button or TouchableOpacity component. You handle the tap by providing an onPress prop with a function. For example: <Button title='Tap' onPress={() => alert('Tapped!')} />.",
          "keyPoints": [
            "Mentions Button/Touchable components",
            "Describes using onPress event",
            "Includes a code example"
          ]
        }
      ]
    },
    {
      "id": "b8e7d7c2-4f9a-4eeb-8c2e-6a8a6d8d9d6f",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "faang",
      "title": "Debugging a Slow List View in Android",
      "description": "A user reports that scrolling in a list view in your Android app feels sluggish. What steps would you take to diagnose and resolve the performance issue?",
      "prompt": "Imagine a list view in an Android app is slow to scroll. Explain how you would identify the cause and improve the performance.",
      "topic": "mobile",
      "subtopics": [
        "android",
        "performance",
        "debugging"
      ],
      "tags": [
        "android",
        "performance",
        "debugging",
        "recyclerview"
      ],
      "estimatedTimeMinutes": 8,
      "aiEvaluationHint": "A strong answer covers using tools like Android Profiler, checking for expensive operations in onBindViewHolder, avoiding complex layouts, proper view recycling, and possible use of DiffUtil. Partial credit for identifying only some causes or only generic solutions.",
      "companies": [
        {
          "name": "Google",
          "logo": "SiGoogle",
          "size": [
            "faang"
          ],
          "description": "Global leader in Android OS and mobile technologies."
        }
      ],
      "positions": [
        "mobile"
      ],
      "primaryTechStack": [
        "android",
        "kotlin",
        "java"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "competitive"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-20T09:02:00Z",
      "updatedAt": "2024-06-20T09:02:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "87fc45c7-2a53-4e7f-8a7a-02f7a5c2c6db",
          "text": "I would profile the list view using Android Profiler to find bottlenecks. Id check for heavy operations in onBindViewHolder, ensure images are loaded efficiently (e.g., using Glide), minimize layout complexity, and confirm view recycling is working. If needed, use DiffUtil for better updates.",
          "keyPoints": [
            "Profiling with Android tools",
            "Optimizing data binding and image loading",
            "Reducing layout complexity",
            "Ensuring view recycling"
          ]
        }
      ]
    },
    {
      "id": "c2e1f9ab-3d06-4b2a-9e64-5f1bcd8e9b2c",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "startup",
      "title": "State Management in Flutter Apps",
      "description": "Explain how state is managed in a Flutter application. Give one example of a common state management approach.",
      "prompt": "Describe the concept of state management in Flutter apps. Name and briefly explain one popular state management solution.",
      "topic": "mobile",
      "subtopics": [
        "flutter",
        "state management"
      ],
      "tags": [
        "flutter",
        "state management",
        "junior"
      ],
      "estimatedTimeMinutes": 7,
      "aiEvaluationHint": "A good answer mentions the importance of state in Flutter, describes setState for local state, and/or names a common package like Provider, Riverpod, or Bloc. Full credit for describing how a package works. Partial for only mentioning setState or not connecting to real use.",
      "companies": null,
      "positions": [
        "mobile"
      ],
      "primaryTechStack": [
        "flutter",
        "dart"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-20T09:03:00Z",
      "updatedAt": "2024-06-20T09:03:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ecf7c8e4-0d63-4c8a-9f2f-1bccf3e7fc6d",
          "text": "State in Flutter can be managed locally with setState or globally with packages like Provider. Provider allows widgets to listen to and react to changes in shared data, simplifying complex app state.",
          "keyPoints": [
            "Explains local and global state",
            "Names Provider as a solution",
            "Describes how Provider works"
          ]
        }
      ]
    },
    {
      "id": "e8e2f3bf-8c2d-4a0b-90db-7e92ffed2ab6",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Implementing Offline Support in a Mobile App",
      "description": "Your mobile app needs to work reliably even when the device is offline. What strategies can you use to support offline functionality?",
      "prompt": "Explain how you would design a mobile app to function offline. List and briefly describe at least two key strategies or technologies.",
      "topic": "mobile",
      "subtopics": [
        "offline",
        "sync",
        "user experience"
      ],
      "tags": [
        "offline",
        "sync",
        "storage",
        "usability"
      ],
      "estimatedTimeMinutes": 8,
      "aiEvaluationHint": "Look for strategies like local caching (SQLite, Realm, CoreData), background sync, queueing changes for later upload, and clear user feedback. Full credit for naming at least two and describing how they help. Partial credit for only one or superficial explanation.",
      "companies": [
        {
          "name": "Spotify",
          "logo": "SiSpotify",
          "size": [
            "enterprise"
          ],
          "description": "Music streaming platform with strong offline capabilities."
        }
      ],
      "positions": [
        "mobile"
      ],
      "primaryTechStack": [
        "kotlin",
        "swift",
        "react-native",
        "flutter"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-20T09:04:00Z",
      "updatedAt": "2024-06-20T09:04:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "b4ae0e4d-1e55-4117-b6e4-379e47d0c5d7",
          "text": "I would use local storage (like SQLite or Realm) to cache data for offline access. For actions made offline, Id queue changes and sync them with the server when back online. Its also important to show users when the app is offline.",
          "keyPoints": [
            "Local storage/caching",
            "Queued sync for changes",
            "User feedback"
          ]
        }
      ]
    },
    {
      "id": "d3a8f1e1-9a5d-4c23-8c2d-1f4e5d6b8c7e",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "faang",
      "title": "Ensuring Accessibility in Mobile Applications",
      "description": "How do you ensure that your mobile app is accessible to users with disabilities? Provide at least two techniques or best practices.",
      "prompt": "Describe concrete steps or techniques you use to improve accessibility in mobile applications. Include examples where possible.",
      "topic": "mobile",
      "subtopics": [
        "accessibility",
        "ui",
        "best practices"
      ],
      "tags": [
        "accessibility",
        "a11y",
        "ui",
        "mobile"
      ],
      "estimatedTimeMinutes": 7,
      "aiEvaluationHint": "Expect mention of screen reader support, proper labeling (content descriptions or accessibility labels), sufficient color contrast, and touch target size. Full credit for listing and describing at least two techniques. Penalize answers that only list without explanation.",
      "companies": [
        {
          "name": "Apple",
          "logo": "SiApple",
          "size": [
            "faang"
          ],
          "description": "Innovator in accessible mobile technology."
        }
      ],
      "positions": [
        "mobile"
      ],
      "primaryTechStack": [
        "swift",
        "kotlin",
        "react-native"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-20T09:05:00Z",
      "updatedAt": "2024-06-20T09:05:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "a9b6a7c4-3f47-4a0f-8e9d-4e2a5d8b9c6f",
          "text": "I ensure all interactive elements have accessibility labels and support screen readers. I also check color contrast and make sure touch targets are large enough. Testing with built-in accessibility tools is important.",
          "keyPoints": [
            "Accessibility labels/screen reader support",
            "Color contrast",
            "Touch target size",
            "Testing with accessibility tools"
          ]
        }
      ]
    },
    {
      "id": "ec2fc6e4-91c2-4b4e-898d-3d7bdcbf5d0e",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "startup",
      "title": "Handling Push Notifications Across Platforms",
      "description": "Describe the challenges of implementing push notifications in a cross-platform mobile app (e.g., React Native or Flutter), and how you would address them.",
      "prompt": "Discuss common challenges when implementing push notifications for both iOS and Android in a cross-platform mobile application. Explain how you would design the notification system to ensure reliable and consistent behavior across platforms.",
      "topic": "mobile",
      "subtopics": [
        "push notifications",
        "cross-platform",
        "react-native",
        "flutter"
      ],
      "tags": [
        "push notifications",
        "ios",
        "android",
        "cross-platform"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "A strong answer addresses platform-specific differences (APNs vs FCM), background/foreground handling, permission management, notification payload formatting, and potential use of abstraction libraries. Partial for listing only one issue or missing key differences.",
      "companies": null,
      "positions": [
        "mobile"
      ],
      "primaryTechStack": [
        "react-native",
        "flutter",
        "firebase"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "competitive"
      ],
      "seniorityLevels": [
        "mid",
        "junior"
      ],
      "createdAt": "2024-06-20T09:06:00Z",
      "updatedAt": "2024-06-20T09:06:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "e3a2d3b1-3c4d-4c5b-a5e0-8b8ed5c2c9e2",
          "text": "Push notifications require handling APNs on iOS and FCM on Android, with differences in setup and payloads. I would use a library like Firebase Cloud Messaging for abstraction and handle permission requests separately for each platform. Testing on both OSs is important for consistency.",
          "keyPoints": [
            "Platform-specific services (APNs, FCM)",
            "Abstraction with cross-platform libraries",
            "Permission management",
            "Testing across platforms"
          ]
        }
      ]
    },
    {
      "id": "f2c0c1b1-6df6-4b7d-98b9-5f2f1e4d9e7c",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "startup",
      "title": "Diagnosing Memory Leaks in iOS Applications",
      "description": "You notice your iOS app's memory usage keeps increasing over time. Describe your approach to diagnosing and fixing memory leaks.",
      "prompt": "Explain the steps you would take to identify and fix memory leaks in an iOS mobile application.",
      "topic": "mobile",
      "subtopics": [
        "ios",
        "memory management",
        "debugging"
      ],
      "tags": [
        "ios",
        "swift",
        "memory",
        "debugging"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Expect mention of using Xcode Instruments (Leaks/Allocations), checking for strong reference cycles, using weak/unowned references, and systematically testing object deallocation. Full credit for practical debugging steps and remedies.",
      "companies": null,
      "positions": [
        "mobile"
      ],
      "primaryTechStack": [
        "swift",
        "ios"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "junior"
      ],
      "createdAt": "2024-06-20T09:07:00Z",
      "updatedAt": "2024-06-20T09:07:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "c7b2fa4e-5d9f-4a8e-8c5a-7d0b81e2e2e1",
          "text": "Id use Xcode Instruments (Leaks and Allocations) to track memory usage and find leaks. Then, Id search for strong reference cycles (especially in closures) and fix them using weak or unowned references. Id also verify objects are deallocated as expected.",
          "keyPoints": [
            "Using Xcode Instruments",
            "Checking for reference cycles",
            "Applying weak/unowned references",
            "Testing deallocation"
          ]
        }
      ]
    },
    {
      "id": "e7a9e4cb-5a4b-4b4e-9e3d-4f8d8e1a0b1e",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Securing Sensitive Data Storage on Mobile Devices",
      "description": "What are the best practices for securely storing sensitive user data (such as authentication tokens) on a mobile device?",
      "prompt": "List and explain at least two best practices for securely storing sensitive information like tokens or personal data on mobile devices.",
      "topic": "mobile",
      "subtopics": [
        "security",
        "data storage"
      ],
      "tags": [
        "security",
        "storage",
        "tokens",
        "best practices"
      ],
      "estimatedTimeMinutes": 9,
      "aiEvaluationHint": "Best answers mention secure storage APIs (Keychain/Keystore), avoiding plain text or shared preferences, not storing sensitive data unnecessarily, and protecting against reverse engineering. Full credit for at least two clearly explained techniques.",
      "companies": [
        {
          "name": "Stripe",
          "logo": "SiStripe",
          "size": [
            "enterprise"
          ],
          "description": "Global payments company with high security requirements."
        }
      ],
      "positions": [
        "mobile"
      ],
      "primaryTechStack": [
        "kotlin",
        "swift",
        "react-native"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-20T09:08:00Z",
      "updatedAt": "2024-06-20T09:08:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "b3e9c7e4-1f7a-4d2f-8e3a-8f0d1c2e9d6a",
          "text": "Store sensitive data using the device's secure storage (iOS Keychain, Android Keystore). Never store tokens in plain text or shared preferences. Limit data retention and use obfuscation to make reverse engineering harder.",
          "keyPoints": [
            "Use secure storage APIs",
            "Avoid plain text/shared preferences",
            "Limit retention/obfuscate code"
          ]
        }
      ]
    },
    {
      "id": "f8d0a1b2-3c5e-4e4a-97e4-3e8b2c0e4f6d",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "senior",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Architecting a Modular Mobile Codebase for Scale",
      "description": "You are leading the mobile team at a fast-growing company. How would you design your app's architecture to support rapid feature development, code reuse, and team scalability as the product grows?",
      "prompt": "Imagine you are responsible for designing the architecture of a large-scale mobile application. Explain the architectural decisions and patterns you would adopt to enable modularity, code reuse, and support multiple teams working in parallel. Discuss concrete examples and trade-offs.",
      "topic": "mobile",
      "subtopics": [
        "architecture",
        "modularity",
        "scalability",
        "team collaboration"
      ],
      "tags": [
        "architecture",
        "modularization",
        "scalability",
        "teams"
      ],
      "estimatedTimeMinutes": 15,
      "aiEvaluationHint": "Full answers should discuss modularization (feature modules/libraries), clear dependency management, separation of concerns, defining shared core components, CI/CD for modules, and balancing code reuse with autonomy. Penalize answers that ignore real-world team collaboration or scaling.",
      "companies": [
        {
          "name": "Uber",
          "logo": "SiUber",
          "size": [
            "faang"
          ],
          "description": "Large-scale mobile platform with complex modular architecture."
        }
      ],
      "positions": [
        "mobile",
        "fullstack"
      ],
      "primaryTechStack": [
        "kotlin",
        "swift",
        "react-native",
        "flutter"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "competitive"
      ],
      "seniorityLevels": [
        "senior",
        "mid"
      ],
      "createdAt": "2024-06-20T09:09:00Z",
      "updatedAt": "2024-06-20T09:09:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ed1fa4b7-6e3c-4e46-9fba-9b8c8e5c0d1a",
          "text": "Id organize the codebase into feature modules and shared libraries, enforce clean separation of concerns, and use dependency injection for decoupling. Each team owns a module with clear APIs. Shared components (like networking or analytics) are maintained centrally. CI/CD pipelines allow independent releases. The trade-off is increased build complexity and coordination.",
          "keyPoints": [
            "Feature modules/libraries",
            "Clear APIs and ownership",
            "Dependency injection",
            "Shared core components",
            "CI/CD for modules",
            "Trade-offs (build complexity, coordination)"
          ]
        }
      ]
    },
    {
      "id": "e1b7c7a2-8d5c-4e28-96e7-60a4b1a4c8f2",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Explain the Difference Between OLTP and OLAP in Data Engineering",
      "description": "Describe the key differences between OLTP (Online Transaction Processing) and OLAP (Online Analytical Processing) systems, and provide a real-world example where each would be most appropriate in a data engineering context.",
      "prompt": "Explain, in your own words, the primary differences between OLTP and OLAP systems. Include one example scenario for each where it would be the preferred approach in a data engineering project.",
      "topic": "data-engineer",
      "subtopics": [
        "databases",
        "data-modeling",
        "fundamentals"
      ],
      "tags": [
        "oltp",
        "olap",
        "database",
        "data-warehousing"
      ],
      "estimatedTimeMinutes": 7,
      "aiEvaluationHint": "A strong answer distinguishes OLTP (transactional, high write, normalized, fast queries for CRUD operations) from OLAP (analytical, heavy reads, denormalized, complex aggregations). The answer should include a scenario for each (e.g., e-commerce order processing for OLTP, business reporting for OLAP). Penalize if candidate does not clearly differentiate or misses practical examples.",
      "companies": [
        {
          "name": "Amazon",
          "logo": "SiAmazon",
          "size": [
            "faang",
            "enterprise"
          ],
          "description": "Global leader in e-commerce and cloud computing."
        }
      ],
      "positions": [
        "data-engineer"
      ],
      "primaryTechStack": [
        "postgresql",
        "mysql",
        "snowflake"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-18T09:00:00Z",
      "updatedAt": "2024-06-18T09:00:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "b8c2f2e7-9b2e-43f6-984a-6b3fa7e9e1d0",
          "text": "OLTP systems are designed for handling many short online transactions such as insert, update, and delete operationsthink of banking systems or e-commerce checkout. OLAP systems, on the other hand, are optimized for complex queries and analytics, often scanning large volumes of historical data, such as generating sales reports over time. For example, an e-commerce website uses OLTP to record each purchase immediately, while its business analytics team uses OLAP to analyze sales trends over months.",
          "keyPoints": [
            "OLTP: transactional, fast CRUD, normalized data",
            "OLAP: analytical, aggregation-heavy, denormalized data",
            "Example for each context"
          ]
        }
      ]
    },
    {
      "id": "d37c85f4-891d-4eaf-8c1a-0e4430e0c7c7",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Describe ETL and ELT: Key Steps and Differences",
      "description": "What are ETL and ELT in the context of data pipelines? Explain the main steps involved in each and highlight their key differences.",
      "prompt": "Describe what ETL and ELT stand for in data engineering, outline the main steps in each process, and explain the primary differences.",
      "topic": "data-engineer",
      "subtopics": [
        "etl",
        "elt",
        "data-pipelines",
        "fundamentals"
      ],
      "tags": [
        "etl",
        "elt",
        "pipeline",
        "transformation"
      ],
      "estimatedTimeMinutes": 7,
      "aiEvaluationHint": "The answer should correctly expand ETL (Extract, Transform, Load) and ELT (Extract, Load, Transform), list the steps in each, and explain the operational difference: ETL transforms data before loading into storage, ELT loads raw data and transforms later, usually in the data warehouse. Penalize confusion between the two or missing key steps.",
      "companies": [
        {
          "name": "Microsoft",
          "logo": "SiMicrosoft",
          "size": [
            "faang",
            "enterprise"
          ],
          "description": "Major provider of cloud and enterprise data solutions."
        }
      ],
      "positions": [
        "data-engineer"
      ],
      "primaryTechStack": [
        "azure-data-factory",
        "databricks",
        "snowflake"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-18T09:01:00Z",
      "updatedAt": "2024-06-18T09:01:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "1a3e5a19-1e89-4b62-9b2e-2c7d6d3f4e56",
          "text": "ETL stands for Extract, Transform, Load: data is extracted from sources, transformed to fit the destination schema, then loaded into the target system. ELT stands for Extract, Load, Transform: data is extracted and loaded in its raw form, then transformed inside the destination (like a data warehouse). The main difference is when and where the transformation happens.",
          "keyPoints": [
            "ETL: Transform before loading",
            "ELT: Load raw, transform in storage",
            "List correct steps for each"
          ]
        }
      ]
    },
    {
      "id": "6c7bf6c5-7c84-4975-b3c3-4d9a2e5e7b9f",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "faang",
      "title": "Choosing Storage Formats: Parquet vs. CSV",
      "description": "You are tasked with storing large volumes of event log data. Explain the trade-offs between using Parquet and CSV formats for this purpose. When should you prefer one over the other?",
      "prompt": "Discuss the advantages and disadvantages of storing event log data in Parquet versus CSV. Under what circumstances should you choose Parquet over CSV, and vice versa?",
      "topic": "data-engineer",
      "subtopics": [
        "data-formats",
        "storage",
        "performance"
      ],
      "tags": [
        "parquet",
        "csv",
        "data-format",
        "storage",
        "compression"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Look for mention of Parquet's columnar storage, better compression, and efficiency for analytics (especially with tools like Spark), versus CSV's simplicity and compatibility. Penalize if candidate doesn't mention ease of use or performance/scalability considerations. Full credit if scenarios for each are provided.",
      "companies": [
        {
          "name": "Google Cloud",
          "logo": "SiGooglecloud",
          "size": [
            "faang",
            "enterprise"
          ],
          "description": "Provider of scalable cloud and analytics solutions."
        }
      ],
      "positions": [
        "data-engineer"
      ],
      "primaryTechStack": [
        "parquet",
        "csv",
        "bigquery",
        "spark"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-18T09:02:00Z",
      "updatedAt": "2024-06-18T09:02:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "b7a1ff89-2341-4252-8e02-19a8f57d9a87",
          "text": "Parquet is columnar, supports efficient compression, and is optimized for analytical queries on big data platforms. CSV is row-based, easy to read and write, and widely supported but less efficient for large-scale analytics or storage. Use Parquet for big data analytics and when working with tools like Spark or BigQuery. Use CSV for simple data interchange or small datasets.",
          "keyPoints": [
            "Parquet: columnar, compressed, efficient analytics",
            "CSV: simple, universal compatibility, less performance",
            "When to use each"
          ]
        }
      ]
    },
    {
      "id": "3b6a7c2b-0f4d-4b7e-8d9e-ff2e3f8e6b76",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "faang",
      "title": "Building a Reliable Data Pipeline: Dealing with Late-Arriving Data",
      "description": "You are designing a batch data pipeline that ingests user activity logs from multiple sources. Some log files may arrive hours or even a day late. How would you design the pipeline to ensure data completeness and consistency despite late-arriving data?",
      "prompt": "Propose a strategy for handling late-arriving data in a batch pipeline for user activity logs. Discuss how your solution ensures no data is lost and analytics remain accurate.",
      "topic": "data-engineer",
      "subtopics": [
        "data-pipeline",
        "batch-processing",
        "data-quality"
      ],
      "tags": [
        "late-data",
        "batch",
        "pipeline",
        "data-integrity"
      ],
      "estimatedTimeMinutes": 12,
      "aiEvaluationHint": "A strong answer discusses windowing strategies (e.g., processing with a delay or reprocessing late files), data deduplication, and possibly watermarking. Penalize if candidate does not consider data completeness or how to update analytics with late data. Full credit if they describe how to avoid double-counting.",
      "companies": [
        {
          "name": "Netflix",
          "logo": "SiNetflix",
          "size": [
            "faang",
            "enterprise"
          ],
          "description": "Streaming platform with large-scale data pipelines."
        }
      ],
      "positions": [
        "data-engineer"
      ],
      "primaryTechStack": [
        "spark",
        "airflow",
        "hadoop"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-18T09:03:00Z",
      "updatedAt": "2024-06-18T09:03:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "a5e5c2d0-4d8e-4a1c-9364-d9f6f827e833",
          "text": "Implement a late data handling mechanism, such as holding the processing window open for a set delay or reprocessing partitions when late files arrive. Use deduplication to avoid double-counting and update downstream analytics when late data is incorporated. Watermarking can help track the completeness of each batch.",
          "keyPoints": [
            "Processing window delay or reprocessing",
            "Deduplication to ensure accuracy",
            "Watermarking or similar technique"
          ]
        }
      ]
    },
    {
      "id": "872fae9e-8f0e-4c9e-8f45-b9d3c6a7b3a1",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "startup",
      "title": "Ensuring Data Quality in a Data Lake",
      "description": "A startup is building a data lake on cloud storage to centralize data from several departments. What are the essential steps and tools a data engineer should use to maintain data quality in this environment?",
      "prompt": "Outline a plan for ensuring high data quality in a cloud-based data lake. Include specific steps and mention any commonly used tools or frameworks.",
      "topic": "data-engineer",
      "subtopics": [
        "data-lake",
        "data-quality",
        "governance"
      ],
      "tags": [
        "data-quality",
        "validation",
        "data-lake",
        "cloud"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Look for mention of schema enforcement, validation, monitoring, and possibly metadata management. Tools like AWS Glue, Apache Atlas, or Great Expectations can be mentioned. Penalize if answer is vague or omits concrete steps or tools.",
      "companies": [
        {
          "name": "Plandek",
          "logo": "SiPlandek",
          "size": [
            "startup"
          ],
          "description": "Startup focused on analytics and engineering metrics."
        }
      ],
      "positions": [
        "data-engineer"
      ],
      "primaryTechStack": [
        "aws-s3",
        "glue",
        "great-expectations"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-18T09:04:00Z",
      "updatedAt": "2024-06-18T09:04:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "4a2e7b67-7b96-4c08-9baa-5a3d55c3e3c2",
          "text": "To maintain data quality, implement schema validation on data ingestion, use data profiling and quality checks with tools like Great Expectations, and add monitoring for anomalies. Catalog metadata using AWS Glue or Apache Atlas. Set up alerts for failed validations and document data lineage.",
          "keyPoints": [
            "Schema enforcement/validation",
            "Quality checks and monitoring",
            "Use of relevant tools (e.g., Great Expectations, Glue)"
          ]
        }
      ]
    },
    {
      "id": "e5f3b4b2-0b9f-4c7e-b8c1-7b8d2f3f8e2e",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Optimizing Spark Jobs for Performance",
      "description": "You notice that a Spark job processing daily clickstream data is running slower than expected as data volume grows. Describe the steps you would take to diagnose and optimize the jobs performance.",
      "prompt": "Given a Spark job that is slowing down as data grows, describe a systematic approach to identify bottlenecks and optimize performance. Include both code-level and cluster-level improvements.",
      "topic": "data-engineer",
      "subtopics": [
        "spark",
        "performance",
        "optimization"
      ],
      "tags": [
        "spark",
        "performance",
        "tuning",
        "cluster"
      ],
      "estimatedTimeMinutes": 15,
      "aiEvaluationHint": "Look for use of Spark UI/profiling tools, checking for data skew, optimizing joins, partitioning, memory management, and resource allocation. Penalize vague answers or missing multi-level approach. Partial credit for only mentioning code or infra, not both.",
      "companies": [
        {
          "name": "Uber",
          "logo": "SiUber",
          "size": [
            "startup",
            "enterprise"
          ],
          "description": "Global leader in mobility and real-time data processing."
        }
      ],
      "positions": [
        "data-engineer"
      ],
      "primaryTechStack": [
        "spark",
        "hadoop",
        "scala"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "competitive"
      ],
      "seniorityLevels": [
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-18T09:05:00Z",
      "updatedAt": "2024-06-18T09:05:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "c4b6e1d5-2b8d-4e67-9fe6-6de3c9e4cc71",
          "text": "Use Spark UI to identify bottlenecks (e.g., long-running stages, data skew). Repartition data to avoid bottlenecks, optimize joins (use broadcast joins if applicable), and cache intermediate results when reused. At the cluster level, adjust executor memory and core settings, and scale resources as needed.",
          "keyPoints": [
            "Profiling with Spark UI",
            "Tuning partitioning and joins",
            "Memory and cluster configuration"
          ]
        }
      ]
    },
    {
      "id": "2c7abd67-0a7a-4548-9f7c-6f6c8e8d96b7",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Implementing Slowly Changing Dimensions (SCD) in a Data Warehouse",
      "description": "How would you implement Slowly Changing Dimensions (SCD) in a data warehouse to track changes in customer information over time? Discuss at least two types of SCD and when each is appropriate.",
      "prompt": "Explain the concept of Slowly Changing Dimensions in data warehousing. Describe at least two SCD types and how you would implement them to track changes, such as customer address updates.",
      "topic": "data-engineer",
      "subtopics": [
        "data-warehousing",
        "scd",
        "dimensional-modeling"
      ],
      "tags": [
        "scd",
        "data-warehouse",
        "dimensional",
        "history"
      ],
      "estimatedTimeMinutes": 14,
      "aiEvaluationHint": "Expect SCD Type 1 (overwrite) and Type 2 (history with new records), with explanation of when to use each. Look for implementation details (e.g., flag columns, effective dates). Penalize if answer confuses the types or misses use case distinctions.",
      "companies": [
        {
          "name": "Oracle",
          "logo": "SiOracle",
          "size": [
            "enterprise"
          ],
          "description": "Enterprise database and data warehousing provider."
        }
      ],
      "positions": [
        "data-engineer"
      ],
      "primaryTechStack": [
        "oracle",
        "sql-server",
        "snowflake"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-18T09:06:00Z",
      "updatedAt": "2024-06-18T09:06:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "f7e3c6d1-2e6a-4b0c-8e52-3c4a8e5d7c3d",
          "text": "SCD Type 1 simply overwrites old data, so only the latest value is kept (e.g., update address in place). SCD Type 2 keeps historical records by adding new rows with effective dates or version numbers, preserving each change (e.g., track address history). Use Type 1 for corrections, Type 2 for historical analysis.",
          "keyPoints": [
            "SCD Type 1: overwrite, no history",
            "SCD Type 2: new record per change, keeps history",
            "Implementation details and use cases"
          ]
        }
      ]
    },
    {
      "id": "8bda1e2b-98d7-4e69-8d86-11f2b5f6f8a2",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Streaming vs Batch Processing: Architectural Trade-offs",
      "description": "You are asked to design a data ingestion architecture for an IoT platform that collects sensor data in real-time but also needs historical analytics. Compare the trade-offs between using streaming and batch processing, and propose a hybrid approach if appropriate.",
      "prompt": "Compare streaming and batch processing for ingesting IoT sensor data. Discuss their pros and cons, and describe a hybrid architecture that supports both real-time and historical requirements.",
      "topic": "data-engineer",
      "subtopics": [
        "streaming",
        "batch-processing",
        "architecture"
      ],
      "tags": [
        "streaming",
        "batch",
        "iot",
        "architecture",
        "hybrid"
      ],
      "estimatedTimeMinutes": 16,
      "aiEvaluationHint": "Look for clear comparison: streaming (low latency, complexity, cost), batch (simplicity, higher latency). Strong answer proposes a hybrid (e.g., Lambda architecture) and describes how each layer serves different use cases. Penalize if only one mode is discussed or no hybrid is proposed.",
      "companies": [
        {
          "name": "Tesla",
          "logo": "SiTesla",
          "size": [
            "faang",
            "enterprise"
          ],
          "description": "Leader in IoT, connected vehicles, and real-time analytics."
        }
      ],
      "positions": [
        "data-engineer"
      ],
      "primaryTechStack": [
        "kafka",
        "spark",
        "aws-kinesis"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-18T09:07:00Z",
      "updatedAt": "2024-06-18T09:07:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "9e4a6c8c-594b-4a1b-8e5e-6d3b5c7e8f1b",
          "text": "Streaming enables low-latency, near real-time processing but is more complex and may incur higher costs. Batch processing is simpler and more cost-effective for large historical datasets but has higher latency. A hybrid (Lambda) architecture uses streaming for real-time monitoring and batch for comprehensive analytics.",
          "keyPoints": [
            "Pros/cons of streaming vs batch",
            "Hybrid approach (e.g., Lambda architecture)",
            "Serving both real-time and historical needs"
          ]
        }
      ]
    },
    {
      "id": "d134be3c-27e1-4d21-b3fd-7b5e3cd9c2c8",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Data Lineage and Its Importance",
      "description": "Explain what data lineage is in the context of data engineering. Why is it important, and how would you implement lineage tracking in a complex data platform?",
      "prompt": "Define data lineage and discuss its significance. Outline practical ways to implement and maintain data lineage in a modern data engineering stack.",
      "topic": "data-engineer",
      "subtopics": [
        "data-lineage",
        "governance",
        "metadata"
      ],
      "tags": [
        "data-lineage",
        "governance",
        "metadata",
        "traceability"
      ],
      "estimatedTimeMinutes": 13,
      "aiEvaluationHint": "Look for clear definition (tracking data origin, movement, transformations), reasons (audit, debugging, compliance), and mention of tools (OpenLineage, Apache Atlas, built-in platform features). Penalize if missing either the why or the how.",
      "companies": [
        {
          "name": "IBM",
          "logo": "SiIbm",
          "size": [
            "enterprise"
          ],
          "description": "Longstanding leader in data management and analytics."
        }
      ],
      "positions": [
        "data-engineer"
      ],
      "primaryTechStack": [
        "apache-atlas",
        "openlineage",
        "airflow"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-18T09:08:00Z",
      "updatedAt": "2024-06-18T09:08:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "c2e8b1a7-12f4-4a8d-9e3e-4b7f9c7f8b1e",
          "text": "Data lineage refers to tracking the origin, movement, and transformations of data through all stages. It's important for auditing, debugging, and regulatory compliance. Implement using metadata catalog tools like Apache Atlas or OpenLineage, and automate lineage capture in ETL workflows.",
          "keyPoints": [
            "Definition of data lineage",
            "Importance: audit, compliance, debugging",
            "Tools and automation strategies"
          ]
        }
      ]
    },
    {
      "id": "5e8d6a9b-da5a-4f8c-8e6b-5c7e2d9a1b4c",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "senior",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Designing Fault-Tolerant Data Pipelines in the Cloud",
      "description": "A global streaming company needs to build a data pipeline that ingests, processes, and stores user activity data in real time. The pipeline must handle spikes in traffic, partial failures, and ensure data is not lost or duplicated. How would you design such a system for reliability and scalability?",
      "prompt": "Describe your approach to architecting a real-time data pipeline for a global streaming platform with strict requirements for fault tolerance, scalability, and exactly-once processing. Include choices of technologies, recovery mechanisms, and monitoring.",
      "topic": "data-engineer",
      "subtopics": [
        "architecture",
        "fault-tolerance",
        "streaming",
        "cloud"
      ],
      "tags": [
        "fault-tolerance",
        "streaming",
        "pipeline",
        "scalability",
        "cloud"
      ],
      "estimatedTimeMinutes": 22,
      "aiEvaluationHint": "Expect a design including scalable ingestion (Kafka/Kinesis), distributed processing (Spark/Flink), durable storage (S3/BigQuery), and components for monitoring and alerting. The answer should cover error handling, retries, idempotency or deduplication, and discuss exactly-once guarantees. Penalize if answer omits how to handle partial failures or scalability.",
      "companies": [
        {
          "name": "Spotify",
          "logo": "SiSpotify",
          "size": [
            "faang",
            "startup"
          ],
          "description": "Global leader in streaming with massive real-time data needs."
        }
      ],
      "positions": [
        "data-engineer"
      ],
      "primaryTechStack": [
        "kafka",
        "flink",
        "aws-s3",
        "cloudwatch"
      ],
      "interviewTypes": [
        "regular",
        "competitive",
        "teacher"
      ],
      "seniorityLevels": [
        "senior"
      ],
      "createdAt": "2024-06-18T09:09:00Z",
      "updatedAt": "2024-06-18T09:09:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "f6a8e1b2-68c7-4e5b-9a8d-4b3e7f8b2d1a",
          "text": "Ingest data with Kafka for high throughput and durability. Use Apache Flink or Spark Structured Streaming for distributed processing with exactly-once semantics. Store data in S3 or BigQuery for durability and scalability. Implement idempotent processing and deduplication to avoid duplicates, and use monitoring (CloudWatch) with alerting on failures. Design for retries and graceful recovery from partial failures.",
          "keyPoints": [
            "Scalable, durable ingestion (Kafka/Kinesis)",
            "Distributed, fault-tolerant processing (Flink/Spark)",
            "Durable storage (S3/BigQuery)",
            "Exactly-once guarantees, deduplication, monitoring"
          ]
        }
      ]
    },
    {
      "id": "1e2f3a4b-5c6d-7e8f-9a01-2b3c4d5e6f70",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Explain the difference between supervised and unsupervised learning",
      "description": "As a data scientist, you are often asked to use machine learning techniques. Explain the difference between supervised and unsupervised learning, including examples of when you might use each.",
      "prompt": "Explain the difference between supervised and unsupervised learning, and provide a scenario for each where it would be appropriate to use.",
      "topic": "data-scientist",
      "subtopics": [
        "machine-learning",
        "fundamentals"
      ],
      "tags": [
        "supervised-learning",
        "unsupervised-learning",
        "ml-basics"
      ],
      "estimatedTimeMinutes": 5,
      "aiEvaluationHint": "A strong answer should clearly define both supervised and unsupervised learning, provide an appropriate example for each, and describe a typical use case. Penalize answers that mix up the definitions or fail to provide examples.",
      "companies": [
        {
          "name": "Google",
          "logo": "SiGoogle",
          "size": [
            "faang"
          ],
          "description": "A global technology leader in search, AI, and cloud computing."
        }
      ],
      "positions": [
        "data-scientist"
      ],
      "primaryTechStack": [
        "python",
        "scikit-learn"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-10T09:00:00Z",
      "updatedAt": "2024-06-10T09:00:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ref1",
          "text": "Supervised learning uses labeled data to train models, such as classifying emails as spam or not spam. Unsupervised learning uses unlabeled data to find patterns, such as clustering customers by behavior.",
          "keyPoints": [
            "Supervised learning uses labeled data",
            "Unsupervised learning uses unlabeled data",
            "Provides an example for each"
          ]
        }
      ]
    },
    {
      "id": "b4a2c3d4-e5f6-7a8b-9c0d-1e2f3a4b5c67",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "startup",
      "title": "Describe the role of feature engineering in data science projects",
      "description": "Briefly explain what feature engineering is and why it is important in building effective machine learning models.",
      "prompt": "What is feature engineering in the context of data science? Why is it important for machine learning? Give a simple example.",
      "topic": "data-scientist",
      "subtopics": [
        "feature-engineering",
        "practices"
      ],
      "tags": [
        "feature-selection",
        "ml"
      ],
      "estimatedTimeMinutes": 5,
      "aiEvaluationHint": "Look for an explanation that defines feature engineering, discusses its impact on model performance, and provides an example. Penalize answers that only repeat the term or do not explain its value.",
      "companies": [
        {
          "name": "Airbnb",
          "logo": "SiAirbnb",
          "size": [
            "startup"
          ],
          "description": "A platform for booking unique accommodations and experiences."
        }
      ],
      "positions": [
        "data-scientist"
      ],
      "primaryTechStack": [
        "python",
        "pandas"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "flash"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-10T09:02:00Z",
      "updatedAt": "2024-06-10T09:02:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ref1",
          "text": "Feature engineering involves creating new input features or modifying existing ones to improve model performance. For example, converting a date into day-of-week and month features.",
          "keyPoints": [
            "Defines feature engineering",
            "Mentions impact on model performance",
            "Provides a practical example"
          ]
        }
      ]
    },
    {
      "id": "c9d8e7f6-5b4a-3c2d-1e0f-9a8b7c6d5e4f",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "faang",
      "title": "Handling missing data in a dataset",
      "description": "Suppose you receive a dataset with several missing values in critical columns. Describe at least two strategies for handling missing data and discuss when each might be appropriate.",
      "prompt": "Describe at least two different approaches to handling missing data in a dataset. For each, explain when it is appropriate to use that strategy.",
      "topic": "data-scientist",
      "subtopics": [
        "data-cleaning",
        "data-preprocessing"
      ],
      "tags": [
        "missing-values",
        "data-preprocessing"
      ],
      "estimatedTimeMinutes": 8,
      "aiEvaluationHint": "Expect description of at least two strategies, such as imputation and removal. Answers should mention the trade-offs or when to use each. Partial credit for describing only one method.",
      "companies": [
        {
          "name": "Microsoft",
          "logo": "SiMicrosoft",
          "size": [
            "faang"
          ],
          "description": "A global leader in software, cloud, and AI technologies."
        }
      ],
      "positions": [
        "data-scientist"
      ],
      "primaryTechStack": [
        "python",
        "pandas"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-10T09:05:00Z",
      "updatedAt": "2024-06-10T09:05:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ref1",
          "text": "You can drop rows or columns with missing values if the missingness is small and random. Alternatively, you can use imputation (e.g., filling with mean, median, or predicted values), which is useful when data is missing at random and you want to preserve data size.",
          "keyPoints": [
            "Describes dropping rows/columns",
            "Describes imputation",
            "Mentions when each approach is suitable"
          ]
        }
      ]
    },
    {
      "id": "d7e6f5a4-b3c2-1d0e-9f8a-7b6c5d4e3a2b",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Evaluating model performance beyond accuracy",
      "description": "You have built a binary classification model with 95% accuracy. However, the dataset is imbalanced. What other metrics should you use to evaluate your model, and why?",
      "prompt": "In the case of an imbalanced binary classification problem, discuss at least two evaluation metrics (besides accuracy) and explain why they are important.",
      "topic": "data-scientist",
      "subtopics": [
        "model-evaluation",
        "classification"
      ],
      "tags": [
        "imbalanced-data",
        "evaluation-metrics"
      ],
      "estimatedTimeMinutes": 8,
      "aiEvaluationHint": "Look for metrics such as precision, recall, F1-score, ROC-AUC, and a brief explanation of why accuracy can be misleading for imbalanced data. Partial credit if only one metric is discussed.",
      "companies": [
        {
          "name": "IBM",
          "logo": "SiIbm",
          "size": [
            "enterprise"
          ],
          "description": "A leading enterprise in cloud, AI, and analytics solutions."
        }
      ],
      "positions": [
        "data-scientist"
      ],
      "primaryTechStack": [
        "python",
        "scikit-learn"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "flash",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-10T09:07:00Z",
      "updatedAt": "2024-06-10T09:07:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ref1",
          "text": "Precision and recall are important for imbalanced datasets. Precision measures the proportion of positive predictions that are correct, while recall measures the proportion of actual positives captured. F1-score combines both. ROC-AUC is also useful for assessing model discrimination.",
          "keyPoints": [
            "Mentions at least two metrics (precision, recall, F1, ROC-AUC)",
            "Explains why accuracy is insufficient for imbalance",
            "Briefly defines the alternative metrics"
          ]
        }
      ]
    },
    {
      "id": "e2f3a4b5-c6d7-8e9f-0a1b-2c3d4e5f6a7b",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "startup",
      "title": "Approach to exploratory data analysis (EDA)",
      "description": "You are given a new dataset and asked to perform exploratory data analysis (EDA). What steps would you take, and what are you looking for during this process?",
      "prompt": "Describe your approach to exploratory data analysis (EDA) when working with a new dataset. List the main steps you would perform and why each is important.",
      "topic": "data-scientist",
      "subtopics": [
        "eda",
        "data-analysis"
      ],
      "tags": [
        "eda",
        "analysis",
        "data-exploration"
      ],
      "estimatedTimeMinutes": 8,
      "aiEvaluationHint": "Expect a logical sequence of EDA steps: data overview, summary statistics, missing values, visualizations, and identifying patterns or anomalies. Award higher credit for clear structure and practical examples.",
      "companies": [
        {
          "name": "Stripe",
          "logo": "SiStripe",
          "size": [
            "startup"
          ],
          "description": "A technology company building economic infrastructure for the internet."
        }
      ],
      "positions": [
        "data-scientist"
      ],
      "primaryTechStack": [
        "python",
        "pandas",
        "matplotlib"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "entry",
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-10T09:10:00Z",
      "updatedAt": "2024-06-10T09:10:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ref1",
          "text": "Start by loading the data and checking its shape and summary statistics. Identify missing or anomalous values, examine distributions with plots, and analyze relationships between variables. These steps help understand the data's structure and potential issues.",
          "keyPoints": [
            "Loading and inspecting data",
            "Checking summary statistics",
            "Identifying missing/anomalous values",
            "Visual exploration",
            "Understanding relationships between variables"
          ]
        }
      ]
    },
    {
      "id": "f1a2b3c4-d5e6-7f8a-9b0c-1d2e3f4a5b6c",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Selecting features for a predictive model",
      "description": "Imagine you are tasked with improving the performance of a regression model by selecting the most relevant features. Describe at least two methods for feature selection and the pros and cons of each.",
      "prompt": "Discuss at least two feature selection methods suitable for regression models. For each method, explain how it works and its advantages and disadvantages.",
      "topic": "data-scientist",
      "subtopics": [
        "feature-selection",
        "model-improvement"
      ],
      "tags": [
        "feature-selection",
        "regression",
        "modeling"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Look for clear descriptions of methods such as filter methods (e.g., correlation), wrapper methods (e.g., recursive feature elimination), or embedded methods (e.g., Lasso). Answers should include pros and cons for each, such as speed, simplicity, and potential for overfitting.",
      "companies": [
        {
          "name": "Netflix",
          "logo": "SiNetflix",
          "size": [
            "faang"
          ],
          "description": "A leading streaming entertainment service and data-driven company."
        }
      ],
      "positions": [
        "data-scientist"
      ],
      "primaryTechStack": [
        "python",
        "scikit-learn"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "competitive",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-10T09:15:00Z",
      "updatedAt": "2024-06-10T09:15:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ref1",
          "text": "Filter methods use statistical measures like correlation to select features; they're fast but may miss feature interactions. Wrapper methods like recursive feature elimination evaluate subsets based on model performance but are computationally expensive. Embedded methods like Lasso combine selection with modeling and can handle multicollinearity.",
          "keyPoints": [
            "Describes at least two methods",
            "Mentions pros/cons (e.g., speed, accuracy, complexity)",
            "Relates to regression context"
          ]
        }
      ]
    },
    {
      "id": "a3b2c1d0-e9f8-7a6b-5c4d-3e2f1a0b9c8d",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Dealing with overfitting in machine learning models",
      "description": "You notice that your machine learning model performs well on training data but poorly on unseen data. What steps would you take to address this overfitting, and why?",
      "prompt": "List and explain at least two techniques to reduce overfitting in machine learning models. For each, describe how it helps improve generalization.",
      "topic": "data-scientist",
      "subtopics": [
        "model-regularization",
        "ml-best-practices"
      ],
      "tags": [
        "overfitting",
        "generalization",
        "regularization"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Strong answers should mention techniques like regularization (L1/L2), cross-validation, or reducing model complexity. Look for explanations of how each method addresses overfitting. Penalize answers that only mention generic steps without explanation.",
      "companies": [
        {
          "name": "SAP",
          "logo": "SiSap",
          "size": [
            "enterprise"
          ],
          "description": "A global leader in enterprise application software."
        }
      ],
      "positions": [
        "data-scientist"
      ],
      "primaryTechStack": [
        "python",
        "scikit-learn"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "competitive",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-10T09:18:00Z",
      "updatedAt": "2024-06-10T09:18:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ref1",
          "text": "Apply regularization techniques (like L1 or L2) to penalize complex models, or use cross-validation to tune hyperparameters and evaluate performance on unseen data. Simplifying the model or using more data can also help.",
          "keyPoints": [
            "Mentions at least two anti-overfitting techniques",
            "Explains how each technique promotes generalization",
            "Goes beyond just listing techniques"
          ]
        }
      ]
    },
    {
      "id": "f4e3d2c1-b0a9-8b7c-6d5e-4f3a2b1c0d9e",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Communicating findings to non-technical stakeholders",
      "description": "You have analyzed a large dataset and found actionable insights that could impact business decisions. How would you present your findings to a group of non-technical stakeholders to ensure your message is clear and impactful?",
      "prompt": "Describe your approach to communicating complex data analysis results to a non-technical audience. What techniques or tools would you use to maximize understanding and engagement?",
      "topic": "data-scientist",
      "subtopics": [
        "data-storytelling",
        "business-communication"
      ],
      "tags": [
        "business-communication",
        "data-visualization"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Look for answers that mention avoiding jargon, using visualizations, focusing on business impact, and tailoring the message to the audience. Higher credit for demonstrating empathy and providing concrete techniques.",
      "companies": [
        {
          "name": "Salesforce",
          "logo": "SiSalesforce",
          "size": [
            "faang"
          ],
          "description": "Cloud-based CRM and data-driven business solutions."
        }
      ],
      "positions": [
        "data-scientist"
      ],
      "primaryTechStack": [
        "tableau",
        "python",
        "matplotlib"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-10T09:20:00Z",
      "updatedAt": "2024-06-10T09:20:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ref1",
          "text": "Focus on business relevance, avoid technical jargon, and use clear visualizations like charts or dashboards. Tell a compelling story that connects the data to business outcomes, and be ready to answer follow-up questions.",
          "keyPoints": [
            "Avoids technical jargon",
            "Uses visualization tools",
            "Links findings to business value",
            "Emphasizes clarity and engagement"
          ]
        }
      ]
    },
    {
      "id": "a8b9c0d1-e2f3-4a5b-6c7d-8e9f0a1b2c3d",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "startup",
      "title": "Pipeline design for scalable data processing",
      "description": "You're working at a startup that expects rapid growth in user activity data. How would you design a data processing pipeline that can scale efficiently as data volume increases?",
      "prompt": "Describe a high-level architecture for a scalable data processing pipeline suitable for a fast-growing product. Include considerations for data ingestion, storage, processing, and monitoring.",
      "topic": "data-scientist",
      "subtopics": [
        "data-engineering",
        "scalability"
      ],
      "tags": [
        "pipeline",
        "scalability",
        "architecture"
      ],
      "estimatedTimeMinutes": 12,
      "aiEvaluationHint": "Look for mention of scalable storage (cloud/data lake), batch vs streaming processing, use of distributed frameworks (e.g., Spark), and monitoring. Strong answers will discuss trade-offs and future-proofing.",
      "companies": [
        {
          "name": "Uber",
          "logo": "SiUber",
          "size": [
            "startup"
          ],
          "description": "A global ride-sharing and mobility platform."
        }
      ],
      "positions": [
        "data-scientist"
      ],
      "primaryTechStack": [
        "python",
        "spark",
        "aws"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "competitive",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-10T09:22:00Z",
      "updatedAt": "2024-06-10T09:22:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ref1",
          "text": "Use a message queue like Kafka for ingestion, store data in scalable storage (S3, data lake), process with distributed frameworks like Spark, and implement monitoring for failures and latency. Design for modularity to add capacity as needed.",
          "keyPoints": [
            "Mentions ingestion, storage, processing, and monitoring",
            "Uses scalable/distributed technologies",
            "Discusses modularity and scalability"
          ]
        }
      ]
    },
    {
      "id": "b1c2d3e4-f5a6-7b8c-9d0e-1f2a3b4c5d6e",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "senior",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Diagnosing a production model drift issue",
      "description": "Your team notices that a deployed recommendation model's performance has steadily declined over the past two months. Walk through your approach to diagnosing and resolving the issue.",
      "prompt": "Describe a systematic approach for identifying, diagnosing, and resolving model drift in a production machine learning system. Include possible causes and long-term prevention strategies.",
      "topic": "data-scientist",
      "subtopics": [
        "model-monitoring",
        "production-systems"
      ],
      "tags": [
        "model-drift",
        "monitoring",
        "production"
      ],
      "estimatedTimeMinutes": 15,
      "aiEvaluationHint": "An excellent answer should include monitoring for drift, investigating data and concept drift, analyzing model inputs/outputs, retraining or feature engineering, and implementing long-term alerts or automated retraining. Penalize answers that miss the multi-step process or lack root cause analysis.",
      "companies": [
        {
          "name": "Amazon",
          "logo": "SiAmazon",
          "size": [
            "faang"
          ],
          "description": "Global leader in e-commerce and cloud machine learning solutions."
        }
      ],
      "positions": [
        "data-scientist"
      ],
      "primaryTechStack": [
        "python",
        "aws",
        "sagemaker"
      ],
      "interviewTypes": [
        "regular",
        "competitive",
        "teacher"
      ],
      "seniorityLevels": [
        "senior"
      ],
      "createdAt": "2024-06-10T09:25:00Z",
      "updatedAt": "2024-06-10T09:25:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ref1",
          "text": "Start by confirming the decline using monitoring metrics. Check for data drift (input distribution changes) and concept drift (label changes). Analyze recent data, retrain or update the model as needed, and implement automated drift detection and retraining pipelines.",
          "keyPoints": [
            "Systematic diagnosis (monitoring, data, concept drift)",
            "Root cause analysis",
            "Short-term fixes (retraining, feature changes)",
            "Long-term prevention (automation, alerts)"
          ]
        }
      ]
    },
    {
      "id": "d3ca1e3b-0d7d-4e6b-a93a-7f6a1c2a1c21",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Explaining the CIA Triad",
      "description": "Briefly define the three components of the CIA triad and explain why each is important in cybersecurity.",
      "prompt": "Define confidentiality, integrity, and availability as they relate to cybersecurity. For each, describe why it is important and give a brief example where possible.",
      "topic": "cybersecurity",
      "subtopics": [
        "fundamentals",
        "security-principles"
      ],
      "tags": [
        "CIA-triad",
        "basics",
        "definitions"
      ],
      "estimatedTimeMinutes": 5,
      "aiEvaluationHint": "A strong answer clearly defines confidentiality, integrity, and availability. It explains why each is important (e.g., confidentiality prevents unauthorized access, integrity ensures data is trustworthy, availability ensures services/data are accessible when needed). Look for simple, accurate examples. Penalize if any component is missing or defined incorrectly.",
      "companies": [
        {
          "name": "Cisco",
          "logo": "SiCisco",
          "size": [
            "enterprise"
          ],
          "description": "A global leader in networking and cybersecurity solutions."
        }
      ],
      "positions": [
        "cybersecurity"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-10T09:00:00Z",
      "updatedAt": "2024-06-10T09:00:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ans-1",
          "text": "Confidentiality means only authorized people can access information. Integrity means data is accurate and hasn't been tampered with. Availability means systems and data are accessible when needed. For example, confidentiality protects personal data from leaks, integrity ensures files aren't altered by attackers, and availability ensures users can access services.",
          "keyPoints": [
            "Defines all three components",
            "Explains importance",
            "Provides simple examples"
          ]
        }
      ]
    },
    {
      "id": "ae7e5c1f-25e1-4e8d-8cbe-3b6f7b2d6e0c",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "startup",
      "title": "Password Security Best Practices",
      "description": "List and briefly explain three best practices for creating and managing strong passwords to protect user accounts.",
      "prompt": "Identify three best practices for password security and explain why each helps protect user accounts.",
      "topic": "cybersecurity",
      "subtopics": [
        "authentication",
        "user-security"
      ],
      "tags": [
        "passwords",
        "best-practices",
        "user-education"
      ],
      "estimatedTimeMinutes": 5,
      "aiEvaluationHint": "Look for three distinct best practices such as using long/complex passwords, not reusing passwords, enabling multi-factor authentication, or using password managers. Explanations should show understanding of why these practices matter. Penalize repetition or vague answers.",
      "companies": [
        {
          "name": "Plandek",
          "logo": "SiPlandek",
          "size": [
            "startup"
          ],
          "description": "Startup providing analytics and engineering metrics platforms."
        }
      ],
      "positions": [
        "cybersecurity"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "flash",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-10T09:01:00Z",
      "updatedAt": "2024-06-10T09:01:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ans-1",
          "text": "Use long and complex passwords to make them harder to guess or brute force. Dont reuse passwords across different sites to limit the damage of a breach. Use a password manager to securely store and generate strong passwords.",
          "keyPoints": [
            "Long/complex passwords",
            "No password reuse",
            "Using password managers"
          ]
        }
      ]
    },
    {
      "id": "b43f9a7c-6f21-4f30-8e6b-fb02d10e1bba",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "faang",
      "title": "Mitigating Phishing Attacks",
      "description": "Describe how phishing attacks typically work and outline three steps an organization can take to reduce the risk of successful phishing.",
      "prompt": "Explain the mechanism of a phishing attack. Suggest three actionable measures an organization could implement to reduce the risk of phishing being successful.",
      "topic": "cybersecurity",
      "subtopics": [
        "social-engineering",
        "user-awareness",
        "email-security"
      ],
      "tags": [
        "phishing",
        "attack-vectors",
        "training"
      ],
      "estimatedTimeMinutes": 8,
      "aiEvaluationHint": "A good answer explains phishing as tricking users into revealing sensitive info via fake communication (e.g., emails). Strong answers recommend user training, email filtering/anti-phishing tools, and reporting mechanisms. Penalize if the answer misses basic prevention steps or misidentifies phishing.",
      "companies": [
        {
          "name": "Google",
          "logo": "SiGoogle",
          "size": [
            "faang"
          ],
          "description": "Global leader in search, ads, and cloud, with a strong cybersecurity focus."
        }
      ],
      "positions": [
        "cybersecurity"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-10T09:02:00Z",
      "updatedAt": "2024-06-10T09:02:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ans-1",
          "text": "Phishing attacks send fake emails or messages that appear legitimate to trick users into giving up information or clicking malicious links. Organizations can train employees on recognizing phishing, use anti-phishing email filters, and provide easy ways to report suspicious messages.",
          "keyPoints": [
            "Clear definition of phishing",
            "User training",
            "Technical controls (filtering)",
            "Reporting process"
          ]
        }
      ]
    },
    {
      "id": "c8e2f4b4-2e8b-42b2-9c6b-4d1a52e2a2ad",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "The Role of Firewalls in Network Security",
      "description": "Explain what a firewall is and describe two ways firewalls can help defend against cyber threats.",
      "prompt": "Describe the purpose of a firewall in cybersecurity. Give two examples of how firewalls help protect networks from threats.",
      "topic": "cybersecurity",
      "subtopics": [
        "network-security",
        "perimeter-security"
      ],
      "tags": [
        "firewall",
        "network",
        "threat-prevention"
      ],
      "estimatedTimeMinutes": 7,
      "aiEvaluationHint": "A correct answer defines firewalls as systems that control incoming/outgoing network traffic. Strong answers mention blocking unauthorized access and filtering malicious content/traffic. Penalize confusion with antivirus or vague definitions.",
      "companies": [
        {
          "name": "Cisco",
          "logo": "SiCisco",
          "size": [
            "enterprise"
          ],
          "description": "A global leader in networking and cybersecurity solutions."
        }
      ],
      "positions": [
        "cybersecurity"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-10T09:03:00Z",
      "updatedAt": "2024-06-10T09:03:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ans-1",
          "text": "A firewall is a security system that monitors and controls network traffic based on rules. It helps prevent unauthorized access and can block traffic from suspicious sources or specific ports.",
          "keyPoints": [
            "Defines firewall role",
            "Blocks unauthorized access",
            "Filters/blocks malicious traffic"
          ]
        }
      ]
    },
    {
      "id": "f1a87a28-0d3a-4f9d-bf2f-9e2e6a0cd3be",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "faang",
      "title": "Detecting and Responding to Malware Infections",
      "description": "Your team suspects that a workstation in the company network has been infected with malware. Outline the steps you would take to confirm, contain, and respond to the incident.",
      "prompt": "Describe the process you would follow if you suspect a workstation is infected with malware. Include steps for confirmation, containment, and response.",
      "topic": "cybersecurity",
      "subtopics": [
        "malware",
        "incident-response"
      ],
      "tags": [
        "malware",
        "detection",
        "response"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Look for steps like: confirming infection (scanning, checking behavior), isolating the device, notifying relevant teams, removing malware, and post-incident review. Answers missing containment or response are incomplete. Penalize if answer is too vague or skips critical steps.",
      "companies": [
        {
          "name": "Microsoft",
          "logo": "SiMicrosoft",
          "size": [
            "faang"
          ],
          "description": "One of the largest technology companies, providing platforms and cybersecurity solutions."
        }
      ],
      "positions": [
        "cybersecurity"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "regular",
        "practice"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-10T09:04:00Z",
      "updatedAt": "2024-06-10T09:04:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ans-1",
          "text": "First, investigate suspicious activity and run a malware scan to confirm infection. If confirmed, disconnect the workstation from the network to contain the spread. Notify the security team, remove the malware using appropriate tools, and review logs to understand how the infection happened.",
          "keyPoints": [
            "Confirmation (scanning/observation)",
            "Containment (isolation)",
            "Notification/response",
            "Remediation steps"
          ]
        }
      ]
    },
    {
      "id": "e2b85167-b5f5-45b2-9d91-3b2b4a0eb6d2",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Securing Web Applications Against SQL Injection",
      "description": "A developer is building a web application that uses a SQL database. What is SQL injection, and what practical steps can be taken to prevent it?",
      "prompt": "Define SQL injection and describe at least two specific actions a developer can take to prevent it in a web application.",
      "topic": "cybersecurity",
      "subtopics": [
        "application-security",
        "web-security",
        "database-security"
      ],
      "tags": [
        "sql-injection",
        "web-app",
        "prevention"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Top answers define SQL injection (attacker manipulates input to execute malicious SQL). Prevention steps should include using parameterized queries/prepared statements and input validation/sanitization. Penalize generic or incomplete answers.",
      "companies": [
        {
          "name": "Salesforce",
          "logo": "SiSalesforce",
          "size": [
            "enterprise"
          ],
          "description": "Cloud-based software company with a focus on enterprise security."
        }
      ],
      "positions": [
        "cybersecurity"
      ],
      "primaryTechStack": [
        "sql"
      ],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-10T09:05:00Z",
      "updatedAt": "2024-06-10T09:05:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ans-1",
          "text": "SQL injection is an attack where an attacker manipulates input to run unwanted SQL commands. To prevent it, developers should use parameterized queries or prepared statements, and validate or sanitize all user input.",
          "keyPoints": [
            "Defines SQL injection",
            "Mentions parameterized queries/prepared statements",
            "Mentions input validation/sanitization"
          ]
        }
      ]
    },
    {
      "id": "a9d7c1f0-56c3-4e31-8617-7cb6e9f6e1f5",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "startup",
      "title": "Evaluating Cloud Security Posture",
      "description": "Your company is moving its infrastructure to the cloud. What are three key security considerations when migrating to a cloud provider, and how can each be addressed?",
      "prompt": "List three important security considerations for migrating to the cloud and explain how to address each.",
      "topic": "cybersecurity",
      "subtopics": [
        "cloud-security",
        "architecture",
        "risk-management"
      ],
      "tags": [
        "cloud",
        "migration",
        "risk"
      ],
      "estimatedTimeMinutes": 12,
      "aiEvaluationHint": "Look for answers such as data encryption (protecting data in transit/at rest), access control (least privilege), and compliance (meeting regulatory requirements). Explanations should address how to implement or mitigate each risk. Penalize shallow or generic responses.",
      "companies": [
        {
          "name": "Cloudflare",
          "logo": "SiCloudflare",
          "size": [
            "startup"
          ],
          "description": "Provider of cloud security and performance solutions."
        }
      ],
      "positions": [
        "cybersecurity"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "regular",
        "practice"
      ],
      "seniorityLevels": [
        "mid",
        "junior"
      ],
      "createdAt": "2024-06-10T09:06:00Z",
      "updatedAt": "2024-06-10T09:06:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ans-1",
          "text": "Key considerations include data encryption (use strong encryption for data in transit and at rest), access control (apply least privilege and strong authentication), and compliance (ensure the provider meets regulatory requirements for your industry).",
          "keyPoints": [
            "Data encryption (how/why)",
            "Access control/least privilege",
            "Compliance/regulatory"
          ]
        }
      ]
    },
    {
      "id": "f5d3e2ab-10c7-4b8a-bafc-8eeb49e5bf61",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Network Segmentation for Enhanced Security",
      "description": "Describe what network segmentation is and explain how it helps limit the impact of a security breach. Include an example scenario.",
      "prompt": "Explain network segmentation and describe its security benefits. Provide an example of how it can limit the impact of a breach.",
      "topic": "cybersecurity",
      "subtopics": [
        "network-security",
        "architecture"
      ],
      "tags": [
        "segmentation",
        "breach-mitigation",
        "network"
      ],
      "estimatedTimeMinutes": 12,
      "aiEvaluationHint": "Look for a definition of segmentation (dividing networks into isolated zones). Strong answers explain containment (attackers limited to one segment) and may give an example (e.g., separating user devices from sensitive servers). Penalize missing example or vague benefits.",
      "companies": [
        {
          "name": "Amazon AWS",
          "logo": "SiAmazonaws",
          "size": [
            "faang"
          ],
          "description": "Cloud computing provider with a focus on secure infrastructure."
        }
      ],
      "positions": [
        "cybersecurity"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "regular",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-10T09:07:00Z",
      "updatedAt": "2024-06-10T09:07:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ans-1",
          "text": "Network segmentation divides a network into smaller, isolated sections. This limits the spread of attacks; for example, if a user workstation is compromised, attackers can't access critical servers in another segment.",
          "keyPoints": [
            "Defines segmentation",
            "Explains containment/limiting lateral movement",
            "Gives concrete scenario/example"
          ]
        }
      ]
    },
    {
      "id": "c11e7be7-9f0d-4b98-9eab-f8b7e7c0c10d",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Implementing Multi-Factor Authentication (MFA)",
      "description": "Explain the concept of multi-factor authentication (MFA) and discuss the benefits and potential usability challenges of implementing MFA in a large organization.",
      "prompt": "Describe what multi-factor authentication is, why it improves security, and discuss one or two challenges organizations face when rolling it out to all employees.",
      "topic": "cybersecurity",
      "subtopics": [
        "authentication",
        "identity-management",
        "usability"
      ],
      "tags": [
        "mfa",
        "authentication",
        "user-experience"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Strong answers define MFA as requiring two or more verification methods (something you know, have, or are), note security benefits (harder for attackers to breach), and discuss challenges like user resistance or device management. Penalize if only benefits or only challenges are mentioned.",
      "companies": [
        {
          "name": "IBM",
          "logo": "SiIbm",
          "size": [
            "enterprise"
          ],
          "description": "Enterprise IT and security services provider."
        }
      ],
      "positions": [
        "cybersecurity"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "junior"
      ],
      "createdAt": "2024-06-10T09:08:00Z",
      "updatedAt": "2024-06-10T09:08:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ans-1",
          "text": "MFA requires users to provide two or more different types of credentials, like a password and a code from a phone. It makes attacks harder even if a password is stolen. Challenges include employee resistance and managing devices for authentication.",
          "keyPoints": [
            "Defines MFA",
            "Explains security benefit",
            "Mentions usability/challenge"
          ]
        }
      ]
    },
    {
      "id": "e1fbc6d7-7f7d-47c3-8e8f-fd5d6b5bb5c1",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "senior",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Incident Response: Coordinating After a Ransomware Attack",
      "description": "Your company has just discovered a ransomware attack affecting several core systems. As the lead cybersecurity engineer, outline your immediate response plan, including coordination with stakeholders, technical actions, and communication strategies.",
      "prompt": "Describe in detail how you would manage the immediate response to a ransomware attack that has impacted critical infrastructure. Include technical steps, coordination with internal/external stakeholders, and communication with employees and possibly the public.",
      "topic": "cybersecurity",
      "subtopics": [
        "incident-response",
        "ransomware",
        "crisis-management"
      ],
      "tags": [
        "ransomware",
        "incident-response",
        "communication"
      ],
      "estimatedTimeMinutes": 18,
      "aiEvaluationHint": "Expect a detailed plan: containment (isolate affected systems), assess scope, preserve evidence, coordinate with IT/legal/PR, communicate clearly to staff, possibly notify authorities or customers. Look for prioritization, clarity, and awareness of both technical and business/communication needs. Penalize if answer is incomplete or focuses solely on technical actions.",
      "companies": [
        {
          "name": "Meta",
          "logo": "SiMeta",
          "size": [
            "faang"
          ],
          "description": "Major social media and technology conglomerate with advanced security teams."
        }
      ],
      "positions": [
        "cybersecurity"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "regular",
        "competitive",
        "teacher"
      ],
      "seniorityLevels": [
        "senior",
        "mid"
      ],
      "createdAt": "2024-06-10T09:09:00Z",
      "updatedAt": "2024-06-10T09:09:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "ans-1",
          "text": "Immediately isolate affected systems to prevent further spread. Assemble the incident response team, including IT, legal, and communications. Preserve forensic evidence. Assess the scope of the attack. Inform leadership and employees. Prepare external communication if customer data is affected, and coordinate with law enforcement as necessary.",
          "keyPoints": [
            "Containment/isolation",
            "Stakeholder coordination (IT, legal, PR)",
            "Evidence preservation",
            "Clear internal/external communication"
          ]
        }
      ]
    },
    {
      "id": "b1f4d6d5-0d5c-43e7-8a3c-1e2b5d1a67f4",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "entry",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Defining a Minimum Viable Product (MVP)",
      "description": "Explain what a Minimum Viable Product (MVP) is and why it is important in product development.",
      "prompt": "Describe the concept of a Minimum Viable Product (MVP) and its role in developing new products. Explain why teams often start with an MVP.",
      "topic": "product",
      "subtopics": [
        "mvp",
        "lean startup",
        "product fundamentals"
      ],
      "tags": [
        "mvp",
        "definition",
        "fundamentals",
        "product management"
      ],
      "estimatedTimeMinutes": 6,
      "aiEvaluationHint": "A strong answer should define MVP as the simplest version of a product that allows a team to collect the maximum amount of validated learning about customers with the least effort. It should mention that MVPs are important for reducing risk, enabling fast feedback, and minimizing wasted resources. Answers that only define MVP without explaining its purpose should receive partial credit.",
      "companies": [
        {
          "name": "Amazon",
          "logo": "SiAmazon",
          "size": [
            "faang",
            "enterprise"
          ],
          "description": "Global leader in e-commerce and cloud computing, known for rapid product iterations."
        }
      ],
      "positions": [
        "product"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "entry",
        "junior"
      ],
      "createdAt": "2024-06-01T10:00:00Z",
      "updatedAt": "2024-06-01T10:00:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "a1e9e90a-8f3e-41e2-9c1c-2d2d5f2b6b4e",
          "text": "An MVP is the most basic version of a product that can be released to customers in order to test key assumptions and gather feedback. It helps teams validate ideas quickly and avoid investing in features users don't need.",
          "keyPoints": [
            "Basic product version",
            "Validates assumptions",
            "Collects feedback",
            "Reduces risk"
          ]
        }
      ]
    },
    {
      "id": "8b7c4e0a-b2f3-4f35-80a9-7f2e6b5b6d8d",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "faang",
      "title": "Prioritizing Features with Limited Resources",
      "description": "Imagine your team can only build three out of ten requested features this quarter. How would you prioritize which features to build?",
      "prompt": "Describe a method you would use to prioritize features when faced with limited resources. Include the criteria you would consider and how you would make the final decision.",
      "topic": "product",
      "subtopics": [
        "prioritization",
        "roadmapping",
        "stakeholder management"
      ],
      "tags": [
        "prioritization",
        "feature selection",
        "decision making",
        "resource constraints"
      ],
      "estimatedTimeMinutes": 8,
      "aiEvaluationHint": "A good answer should mention structured prioritization methods such as RICE, MoSCoW, or ICE. Candidates should discuss considering factors like user impact, business value, technical effort, and dependencies. Answers that only mention personal preference or random selection should not get full credit.",
      "companies": [
        {
          "name": "Google",
          "logo": "SiGoogle",
          "size": [
            "faang",
            "enterprise"
          ],
          "description": "Leading technology company with strong product management practices."
        }
      ],
      "positions": [
        "product"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-01T10:05:00Z",
      "updatedAt": "2024-06-01T10:05:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "c2b7a1f3-5f4e-4d1e-9b5a-6a7e8b9c9e7d",
          "text": "I would use the RICE framework, which scores features based on Reach, Impact, Confidence, and Effort. Id also consult with stakeholders to ensure alignment with business goals and customer needs. Features that drive the most value with reasonable effort would be prioritized.",
          "keyPoints": [
            "Structured method (e.g., RICE)",
            "Business value",
            "User impact",
            "Effort",
            "Stakeholder input"
          ]
        }
      ]
    },
    {
      "id": "a7d8e3c1-1a2b-4b9a-8c7e-2c6d7e8f9b0c",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "startup",
      "title": "Measuring Product Success After Launch",
      "description": "Your team has just launched a new product feature. Which metrics would you track to determine if the feature is successful?",
      "prompt": "List and explain the key metrics you would use to measure the success of a newly launched product feature. Justify your choices.",
      "topic": "product",
      "subtopics": [
        "metrics",
        "launch",
        "product analytics"
      ],
      "tags": [
        "success metrics",
        "product launch",
        "measurement",
        "analytics"
      ],
      "estimatedTimeMinutes": 8,
      "aiEvaluationHint": "Good answers should mention both quantitative and qualitative metrics, such as adoption rate, usage frequency, retention, customer satisfaction, and relevant business KPIs. Candidates should connect metrics to the features objective and explain why each metric matters.",
      "companies": [
        {
          "name": "Airbnb",
          "logo": "SiAirbnb",
          "size": [
            "startup",
            "enterprise"
          ],
          "description": "Innovative platform with a data-driven approach to product management."
        }
      ],
      "positions": [
        "product"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-01T10:10:00Z",
      "updatedAt": "2024-06-01T10:10:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "d9c2b3e5-6f7a-4c1b-8d9e-1b2c3d4e5f6a",
          "text": "I would track metrics like feature adoption rate, frequency of use, customer feedback, and impact on retention. If the feature is meant to drive engagement, Id look at engagement rates and session duration. Qualitative feedback through surveys is also important.",
          "keyPoints": [
            "Adoption rate",
            "Usage frequency",
            "Retention",
            "Customer satisfaction",
            "Feature-specific metrics"
          ]
        }
      ]
    },
    {
      "id": "fa8d1b3e-3a5b-4e1c-98c1-0b9d2c3a4e5f",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,

      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Handling Conflicting Stakeholder Requests",
      "description": "You receive two conflicting requests from marketing and engineering teams. How would you approach resolving this conflict as a product manager?",
      "prompt": "Describe your process for handling and resolving conflicting requirements from different stakeholders. Explain how you would ensure the product vision is not compromised.",
      "topic": "product",
      "subtopics": [
        "stakeholder management",
        "communication",
        "conflict resolution"
      ],
      "tags": [
        "stakeholder",
        "conflict",
        "alignment",
        "negotiation"
      ],
      "estimatedTimeMinutes": 7,
      "aiEvaluationHint": "A strong answer should describe gathering context from both parties, understanding their underlying goals, facilitating discussion, and aligning on the broader product vision. Answers should mention compromise, prioritization, and transparent communication. Answers that suggest simply picking a side without engagement should get only partial credit.",
      "companies": [
        {
          "name": "Microsoft",
          "logo": "SiMicrosoft",
          "size": [
            "faang",
            "enterprise"
          ],
          "description": "Global technology company with cross-functional product teams."
        }
      ],
      "positions": [
        "product"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "junior",
        "mid"
      ],
      "createdAt": "2024-06-01T10:15:00Z",
      "updatedAt": "2024-06-01T10:15:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "e4f7b2c1-7c6d-4a2b-8e9f-0d1b2c3a5e7f",
          "text": "I would meet with both teams to understand their reasoning, clarify the goals behind each request, and look for a solution that supports the product vision. Id facilitate a discussion to find common ground or prioritize based on business value and user needs.",
          "keyPoints": [
            "Understand context",
            "Clarify goals",
            "Facilitate discussion",
            "Product vision",
            "Prioritization"
          ]
        }
      ]
    },
    {
      "id": "e9d2a5c4-2b3e-4f9c-87e2-1c5b7d8a9f0e",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Designing Metrics for a Social Feature",
      "description": "Your team is adding a new 'Share with Friends' feature to a messaging app. What metrics would you define to measure its success, and how would you use the data to iterate on the feature?",
      "prompt": "List the key metrics you would track after launching a 'Share with Friends' feature in a messaging app, and explain how youd use the results to improve the feature.",
      "topic": "product",
      "subtopics": [
        "feature metrics",
        "iteration",
        "social products"
      ],
      "tags": [
        "metrics",
        "iteration",
        "feature design",
        "user engagement"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Answers should mention metrics like number of shares, unique users sharing, share-to-install or share-to-action conversion rates, and user retention. Strong responses discuss using data to identify bottlenecks, test improvements (A/B testing), and iterate. Answers limited to just 'track shares' without deeper analysis should get partial credit.",
      "companies": [
        {
          "name": "Meta",
          "logo": "SiMeta",
          "size": [
            "faang",
            "enterprise"
          ],
          "description": "Social technology company known for data-driven product optimization."
        }
      ],
      "positions": [
        "product"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "junior"
      ],
      "createdAt": "2024-06-01T10:20:00Z",
      "updatedAt": "2024-06-01T10:20:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "f3e5c2b1-2a1b-4e8d-9c1a-3b9d2e1a7c6e",
          "text": "Id track number of shares per user, total shares, conversion from share to app install, and retention of users who shared or received shares. Id use this data to identify if users are finding the feature valuable, and run experiments to improve share rates or conversion.",
          "keyPoints": [
            "Shares per user",
            "Conversion rates",
            "Retention",
            "A/B testing",
            "Iterative improvement"
          ]
        }
      ]
    },
    {
      "id": "2a8e5d7b-1c3d-4f2a-96b8-0e1d4c5f6a7b",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "startup",
      "title": "Launching a Product in a New Market",
      "description": "Your company plans to launch its main product in a new country. What factors would you consider to ensure a successful launch?",
      "prompt": "Describe the key considerations and steps you would take to launch a product in a new geographical market. Explain how you would assess risks and adapt the product as needed.",
      "topic": "product",
      "subtopics": [
        "market entry",
        "localization",
        "risk assessment"
      ],
      "tags": [
        "market launch",
        "localization",
        "risk",
        "product adaptation"
      ],
      "estimatedTimeMinutes": 12,
      "aiEvaluationHint": "Strong answers should mention market research, legal/regulatory compliance, localization (language, culture), pricing, competitor analysis, and user onboarding. Answers should discuss risk assessment and monitoring post-launch metrics. Answers that ignore local user needs or legal issues should get partial credit.",
      "companies": [
        {
          "name": "Uber",
          "logo": "SiUber",
          "size": [
            "startup",
            "enterprise"
          ],
          "description": "Global mobility platform with extensive international product launches."
        }
      ],
      "positions": [
        "product"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "junior",
        "senior"
      ],
      "createdAt": "2024-06-01T10:25:00Z",
      "updatedAt": "2024-06-01T10:25:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "b4e8d3a2-0c7d-4f6b-9e1a-2d3c4b5a6e7f",
          "text": "I would conduct market research, assess regulatory requirements, and localize the product for language and cultural fit. Id analyze competitors and adjust pricing accordingly. To manage risk, Id plan a phased launch and monitor adoption and feedback closely.",
          "keyPoints": [
            "Market research",
            "Legal compliance",
            "Localization",
            "Competitor analysis",
            "Risk management"
          ]
        }
      ]
    },
    {
      "id": "f6e1b4c2-4a9d-49f1-96b8-1e2c3a4d5e6f",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Balancing Short-term and Long-term Product Goals",
      "description": "You are pressured to release quick fixes to hit short-term KPIs, but you believe in investing in a long-term product vision. How would you handle this situation?",
      "prompt": "Explain your approach to balancing urgent short-term goals with the need to invest in a product's long-term vision. Provide examples of how you would communicate and prioritize in this scenario.",
      "topic": "product",
      "subtopics": [
        "strategic planning",
        "product vision",
        "stakeholder management"
      ],
      "tags": [
        "vision",
        "strategy",
        "prioritization",
        "trade-offs"
      ],
      "estimatedTimeMinutes": 11,
      "aiEvaluationHint": "A strong answer should discuss balancing immediate business needs with investment in sustainable solutions. Candidates should mention transparent communication with stakeholders, using frameworks (e.g., product roadmaps), and setting clear priorities. Answers that ignore one side of the trade-off should be penalized.",
      "companies": [
        {
          "name": "Salesforce",
          "logo": "SiSalesforce",
          "size": [
            "enterprise"
          ],
          "description": "CRM platform focused on long-term customer success."
        }
      ],
      "positions": [
        "product"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid",
        "senior"
      ],
      "createdAt": "2024-06-01T10:30:00Z",
      "updatedAt": "2024-06-01T10:30:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "c8a2e1b7-5d4f-4c3b-8e7d-9f0b1a2e3c4d",
          "text": "Id prioritize urgent issues that have immediate business impact, but clearly communicate the importance of long-term investments. Id use a roadmap to show how short-term wins fit into the bigger vision and negotiate trade-offs with stakeholders.",
          "keyPoints": [
            "Balance short/long-term",
            "Stakeholder communication",
            "Roadmapping",
            "Prioritization",
            "Trade-offs"
          ]
        }
      ]
    },
    {
      "id": "7a6b4d3c-2f1e-49c8-93a7-0e8c2d4f6b7a",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "middle",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Defining and Tracking North Star Metrics",
      "description": "What is a North Star Metric in product management, and how would you define and track it for a SaaS platform?",
      "prompt": "Explain the concept of a North Star Metric. Describe a process for selecting and tracking an effective North Star Metric for a SaaS product.",
      "topic": "product",
      "subtopics": [
        "metrics",
        "growth",
        "strategy"
      ],
      "tags": [
        "north star metric",
        "measurement",
        "SaaS",
        "strategy"
      ],
      "estimatedTimeMinutes": 10,
      "aiEvaluationHint": "Answers should define North Star Metric as the single metric that best captures the core value delivered to customers. Strong responses should explain how to select a metric that aligns with product strategy, involves stakeholders, and is actionable. Candidates should mention ongoing tracking and iteration.",
      "companies": [
        {
          "name": "Stripe",
          "logo": "SiStripe",
          "size": [
            "startup",
            "enterprise"
          ],
          "description": "Payment platform with a strong focus on growth metrics for SaaS products."
        }
      ],
      "positions": [
        "product"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "regular",
        "practice",
        "teacher"
      ],
      "seniorityLevels": [
        "mid"
      ],
      "createdAt": "2024-06-01T10:35:00Z",
      "updatedAt": "2024-06-01T10:35:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "d7e3a5c2-6b1d-4f8c-9a3b-2c4f7e8a9d0b",
          "text": "A North Star Metric is the leading indicator of a products long-term success. For SaaS, this might be 'number of active subscriptions' or 'monthly active users.' Id select it based on the main customer value, get alignment from stakeholders, and track it regularly to ensure focus.",
          "keyPoints": [
            "North Star Metric definition",
            "Customer value alignment",
            "Stakeholder buy-in",
            "Ongoing tracking"
          ]
        }
      ]
    },
    {
      "id": "1d3c4a5b-7e6f-4c1a-98b7-2e3d4f5a6b7c",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "senior",
      "isDemoMode": false,
      "companyType": "faang",
      "title": "Evaluating a Pivot in Product Strategy",
      "description": "Your product is missing growth targets after multiple iterations. The leadership team is considering a major pivot to a new market segment. As the product manager, how would you evaluate and recommend whether to pivot or persevere?",
      "prompt": "Describe your framework for deciding whether to pivot the product strategy or continue iterating in the current direction. What data and factors would you consider, and how would you communicate your recommendation?",
      "topic": "product",
      "subtopics": [
        "product strategy",
        "pivot",
        "business analysis"
      ],
      "tags": [
        "pivot",
        "strategy",
        "market analysis",
        "decision making"
      ],
      "estimatedTimeMinutes": 15,
      "aiEvaluationHint": "Strong answers should reference frameworks like Lean Startups 'pivot or persevere' decision. Candidates should discuss analyzing market fit, data trends, customer feedback, competitive landscape, and sunk cost fallacy. They should explain how to involve stakeholders and communicate rationale. Partial credit for answers focusing solely on intuition or limited data.",
      "companies": [
        {
          "name": "Netflix",
          "logo": "SiNetflix",
          "size": [
            "faang",
            "enterprise"
          ],
          "description": "Streaming innovator known for major strategic pivots."
        }
      ],
      "positions": [
        "product"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "regular",
        "competitive",
        "teacher"
      ],
      "seniorityLevels": [
        "senior",
        "mid"
      ],
      "createdAt": "2024-06-01T10:40:00Z",
      "updatedAt": "2024-06-01T10:40:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "e8d1a2c3-7b4e-4f6a-91b2-3c4d5e6f7a8b",
          "text": "I would use the Lean Startup pivot-or-persevere framework, analyze product-market fit, growth metrics, customer feedback, and the competitive landscape. Id weigh opportunity cost and risks, then present a data-driven recommendation to leadership with clear pros and cons.",
          "keyPoints": [
            "Pivot/persevere framework",
            "Data-driven analysis",
            "Customer feedback",
            "Market fit",
            "Stakeholder communication"
          ]
        }
      ]
    },
    {
      "id": "b6a8c3d2-1e7f-4c9b-85a1-2e3c4a5d6f7b",
      "status": "published",
      "reviewerId": null,
      "reviewedAt": null,
      "difficulty": "senior",
      "isDemoMode": false,
      "companyType": "enterprise",
      "title": "Scaling Product Processes for Hypergrowth",
      "description": "Your SaaS product is entering a period of hypergrowth, leading to frequent outages and customer complaints about reliability. As the product manager, how would you address both the immediate and long-term issues of scaling?",
      "prompt": "Explain your approach to managing a SaaS product during hypergrowth when reliability issues arise. Discuss both immediate actions and long-term process or architectural changes you would propose.",
      "topic": "product",
      "subtopics": [
        "scaling",
        "reliability",
        "process improvement"
      ],
      "tags": [
        "scaling",
        "reliability",
        "hypergrowth",
        "incident response"
      ],
      "estimatedTimeMinutes": 15,
      "aiEvaluationHint": "A strong answer should cover immediate customer communication, incident management, coordinating with engineering, and setting up customer support. For the long term, it should include improving reliability, scalable architecture, process automation, and setting SLAs. Penalize answers that ignore either short-term or long-term measures.",
      "companies": [
        {
          "name": "Salesforce",
          "logo": "SiSalesforce",
          "size": [
            "enterprise"
          ],
          "description": "Enterprise SaaS leader with experience scaling product operations."
        }
      ],
      "positions": [
        "product"
      ],
      "primaryTechStack": [],
      "interviewTypes": [
        "regular",
        "competitive",
        "teacher"
      ],
      "seniorityLevels": [
        "senior",
        "mid"
      ],
      "createdAt": "2024-06-01T10:45:00Z",
      "updatedAt": "2024-06-01T10:45:00Z",
      "createdBy": "generated_by_ai",
      "referenceAnswers": [
        {
          "id": "f2c8d5a1-3b7e-4f1c-9a6e-2e3d4c5b8a9f",
          "text": "Id immediately communicate with customers about outages and set up a rapid response team with engineering. For the long term, Id prioritize reliability in the roadmap, implement better monitoring, and work on scalable architecture and processes.",
          "keyPoints": [
            "Immediate incident response",
            "Customer communication",
            "Long-term reliability",
            "Scalable architecture",
            "Process improvements"
          ]
        }
      ]
    }
  ],
  "truefalse_questions": [],
  "matching_questions": [],
  "system_design_questions": []
}