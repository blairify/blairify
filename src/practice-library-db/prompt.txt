You are generating high-quality interview practice questions for a database with the following schema:

[SCHEMA BELOW]
-----------------
{{SCHEMA}}
-----------------

OUTPUT REQUIREMENTS
Generate {{BATCH_SIZE}} new questions.

For this batch, you MUST generate questions only in "open_questions".
The arrays "mcq_questions", "truefalse_questions", "matching_questions", and "system_design_questions" MUST be present but MUST be empty arrays.

For this batch, there is a SINGLE target role topic: "{{ROLE_TOPIC}}".
- Every question MUST have "topic" set to exactly "{{ROLE_TOPIC}}".
- "{{ROLE_TOPIC}}" MUST be one of these allowed role topics (one word, lowercase, no spaces):
  - "frontend" (Frontend Developer)
  - "backend" (Backend Developer)
  - "fullstack" (Full Stack Developer)
  - "devops" (DevOps Engineer)
  - "mobile" (Mobile Developer)
  - "data-engineer" (Data Engineer)
  - "data-scientist" (Data Scientist)
  - "cybersecurity" (Cybersecurity Engineer)
  - "product" (Product Manager)

Across ALL questions in this batch, enforce an approximate mix of difficulties:
- about 25% "entry"
- about 35% "junior"
- about 30% "middle"
- about 10% "senior" (no more than ~10–15% of the batch)

Across ALL questions in this batch, ensure topics are appropriate to the target roles and cover the core sub-areas for that role.

- For engineering roles ("frontend", "backend", "fullstack", "devops", "mobile", "data-engineer", "data-scientist", "cybersecurity"):
  - cover a mix of language/framework fundamentals, debugging, performance, testing, architecture, and system-design aspects relevant to that role.
- For "product":
  - focus on product thinking, trade-offs, metrics, prioritisation, and collaborating with engineering, not low-level coding syntax.

Avoid generating 100% pure syntax trivia: at least half of the questions should be scenario-based or applied.

You MUST return a SINGLE JSON object with EXACTLY these 5 top-level array keys:
- "mcq_questions"
- "open_questions"
- "truefalse_questions"
- "matching_questions"
- "system_design_questions"

Each array may be empty, but the keys MUST always be present.

The shared core fields for every question are:

{
  "id": "string",
  "status": "draft | published | archived",
  "reviewerId": "string or null",
  "reviewedAt": "ISO8601 string or null",

  "difficulty": "entry | junior | middle | senior",
  "isDemoMode": false,
  "companyType": "faang | startup | enterprise",

  "title": "string",
  "description": "string",
  "prompt": "string",

  "topic": "frontend | backend | fullstack | devops | mobile | data-engineer | data-scientist | cybersecurity | product",
  "subtopics": ["string", "..."],
  "tags": ["string", "..."],
  "estimatedTimeMinutes": number,

  "aiEvaluationHint": "string or null",

  "companies": [
    {
      "name": "string",
      "logo": "string",
      "size": ["faang" | "startup" | "enterprise"],
      "description": "string"
    }
  ] or null,

  "positions": ["frontend", "backend", "fullstack", "..."],
  "primaryTechStack": ["react", "typescript", "nodejs", "..."],

  "interviewTypes": ["regular", "practice", "flash", "play", "competitive", "teacher"],
  "seniorityLevels": ["entry", "junior", "mid", "senior"],

  "createdAt": "ISO8601 string",
  "updatedAt": "ISO8601 string",
  "createdBy": "generated_by_ai"
}

Type-specific fields for this batch (open_questions only) are:

"open_questions": [
  {
    // shared core fields...
    "referenceAnswers": [
      {
        "id": "string",
        "text": "string",
        "keyPoints": ["string", "..."]
      }
    ]
  }
]

RULES
- IDs must be unique UUID-like strings.
- In a single batch do not create two questions with identical descriptions.
- Avoid repeating the same concept with only small wording changes.
- Spread topics across different sub-areas of the given technology.
- Use only companies from this list (company name MUST match exactly and logo MUST be a React icon name from react-icons/si):

{{COMPANIES}}
Google
Meta
Amazon
Apple
Netflix
Microsoft
Tesla
Nvidia
Oracle
Salesforce
IBM
Intel
Adobe
SAP
Cisco
X
LinkedIn
Snapchat
TikTok
Reddit
Amazon AWS
Microsoft Azure
Google Cloud
Cloudflare
Vercel
Stripe
Spotify
Uber
Airbnb
Plandek

CONTENT RULES
- Every question MUST include:
  title, description, prompt, topic, difficulty, estimatedTimeMinutes
- description is the human-readable text shown directly to the user as the question.
- prompt is the text we can feed to an AI model for evaluation. It may repeat the description but can also add instructions for how to evaluate answers.
- aiEvaluationHint:
  - MUST be tailored to this specific question (no generic templates).
  - For open and system-design questions, MUST be a non-empty string that can be used directly as guidance for an AI evaluator. It SHOULD:
    - list the key points or aspects a strong answer should mention,
    - note common mistakes or misconceptions to penalize,
    - describe how to judge partial vs full credit.
  - For other question types it MAY be null.
- Include a healthy mix of difficulties in every batch: some entry, some junior, some middle, and some senior questions, following the distribution above.
- Senior questions MUST involve realistic scenarios (architecture, debugging complex issues, trade-offs, or multi-step reasoning), not simple definition or syntax trivia.
- Open questions:
  - MUST appear in open_questions.
  - SHOULD include 1–3 referenceAnswers as examples or guidance.
  - aiEvaluationHint is the primary source of evaluation logic.
- Positions:
  - positions MUST be an array of plain strings (no objects).
  - Use lower-case role slugs like:
    - "frontend"
    - "backend"
    - "fullstack"
    - "devops"
    - "mobile"
    - "data-engineer"
    - "data-scientist"
    - "cybersecurity"
    - "product".
- Interview types:
  - interviewTypes MUST use only: "regular", "practice", "flash", "play", "competitive", "teacher".
  - for MCQ questions: interviewTypes MUST include only "play".
- Seniority levels:
  - seniorityLevels MUST use only: "entry", "junior", "mid", "senior".
- createdBy:
  - MUST always be exactly the string "generated_by_ai" for all questions.
- Keep wording clear, concise, and readable.
- For entry/junior questions, keep scenarios simple and focused on fundamentals.
- For middle/senior questions, use realistic complexity and multi-step reasoning while keeping the text clear.
- Must strictly output valid JSON only, no commentary or markdown.

FINAL INSTRUCTIONS
- Return only JSON, no explanations or markdown, no code fences.
- Use a single JSON object with keys:
  "mcq_questions", "open_questions", "truefalse_questions", "matching_questions", "system_design_questions".
- Do not include trailing commas.
- All string values MUST be double-quoted.

